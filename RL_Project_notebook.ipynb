{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL Project notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2iJsf7-zvM-"
      },
      "source": [
        "# Reinforcement Learning Projcet\n",
        "In this notebook, there are the added runs and experiments shown in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyIPnSG1zvNG"
      },
      "source": [
        "### Imports, initiate environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfl-UIDNgY8W",
        "scrolled": true,
        "outputId": "6b2ba2e1-fd82-4feb-949a-6f756a12fb01"
      },
      "source": [
        "#uncomment if not downloaded.\n",
        "\n",
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33m  WARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZWj2Zz-zvNI",
        "outputId": "17833cfb-c59d-454b-d638-323886324093"
      },
      "source": [
        "import gym\n",
        "import sys\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import namedtuple, deque\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "from torch.distributions import MultivariateNormal\n",
        "\n",
        "\n",
        "# python imports\n",
        "from operator import itemgetter\n",
        "import time\n",
        "\n",
        "\n",
        "# Use GPU is possible else use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "print('State shape: ', env.observation_space.shape)\n",
        "print('Number of Actions: ', env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State shape:  (8,)\n",
            "Number of Actions:  Box(-1.0, 1.0, (2,), float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQ0FDgizvNJ"
      },
      "source": [
        "### Universal parameters\n",
        "some parameters are also specifically for the DQN variants "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxYvoyN8zvNJ"
      },
      "source": [
        "STATE_SIZE = env.observation_space.shape[0] #8\n",
        "ACTION_SIZE = env.action_space.shape[0] # 2 - for continuous application\n",
        "main_egine_actions = [-1.0, 0.33, 0.66, 1.0]\n",
        "left_right_actions = [-1.0, 0, 1.0]\n",
        "ACTIONS = list(itertools.product(main_egine_actions, left_right_actions))\n",
        "DISCRETE_ACTION_SIZE = len(ACTIONS) # for discretization of action space by ACTIONS\n",
        "\n",
        "#These parameters assume all actions has the same high-low\n",
        "ACTION_HIGH = env.action_space.high#[0]\n",
        "ACTION_LOW = env.action_space.low#[0]\n",
        "\n",
        "# Define the agents hyperparameters, incl. Replay Memory\n",
        "\n",
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 64  # minibatch size\n",
        "GAMMA = 0.99  # discount factor\n",
        "TAU = 1e-3  # for soft update of target parameters\n",
        "LR = 5e-4  # learning rate\n",
        "UPDATE_EVERY = 4  # how often to update the network\n",
        "\n",
        "ALPHA = 1\n",
        "INITIAL_BETA = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-N2Ca70zvNK"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVbjlOa5zvNL"
      },
      "source": [
        "#layer initializations\n",
        "def init_layer(layer):\n",
        "    size = layer.weight.data.size()[0]\n",
        "    lim = 1. / np.sqrt(size)\n",
        "    return (-lim,lim)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "#copy model parameters from source to target        \n",
        "def copy_params(source, target):\n",
        "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
        "        target_param.data.copy_(param.data)\n",
        "#print model parameters\n",
        "def print_params(model):\n",
        "    for name, param in self.policy_network.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print (name, param.data)\n",
        "            \n",
        "#seed the environment.\n",
        "def init_seed(seed):\n",
        "    #run this before any agent. checked to stabilize the randomness.\n",
        "    env.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4k6Io4AzvNL"
      },
      "source": [
        "#### Segment tree structure , helper for Prioritized Experience Replay (PER)\n",
        "reduces computation time needed to calculate PER priorities "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXVYJU6G2aBu"
      },
      "source": [
        "import operator\n",
        "\n",
        "\n",
        "class SegmentTree(object):\n",
        "    def __init__(self, capacity, operation, neutral_element):\n",
        "        \"\"\"Build a Segment Tree data structure.\n",
        "        https://en.wikipedia.org/wiki/Segment_tree\n",
        "        Can be used as regular array, but with two\n",
        "        important differences:\n",
        "            a) setting item's value is slightly slower.\n",
        "               It is O(lg capacity) instead of O(1).\n",
        "            b) user has access to an efficient ( O(log segment size) )\n",
        "               `reduce` operation which reduces `operation` over\n",
        "               a contiguous subsequence of items in the array.\n",
        "        Paramters\n",
        "        ---------\n",
        "        capacity: int\n",
        "            Total size of the array - must be a power of two.\n",
        "        operation: lambda obj, obj -> obj\n",
        "            and operation for combining elements (eg. sum, max)\n",
        "            must form a mathematical group together with the set of\n",
        "            possible values for array elements (i.e. be associative)\n",
        "        neutral_element: obj\n",
        "            neutral element for the operation above. eg. float('-inf')\n",
        "            for max and 0 for sum.\n",
        "        \"\"\"\n",
        "        assert capacity > 0 and capacity & (capacity - 1) == 0, \"capacity must be positive and a power of 2.\"\n",
        "        self._capacity = capacity\n",
        "        self._value = [neutral_element for _ in range(2 * capacity)]\n",
        "        self._operation = operation\n",
        "\n",
        "    def _reduce_helper(self, start, end, node, node_start, node_end):\n",
        "        if start == node_start and end == node_end:\n",
        "            return self._value[node]\n",
        "        mid = (node_start + node_end) // 2\n",
        "        if end <= mid:\n",
        "            return self._reduce_helper(start, end, 2 * node, node_start, mid)\n",
        "        else:\n",
        "            if mid + 1 <= start:\n",
        "                return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
        "            else:\n",
        "                return self._operation(\n",
        "                    self._reduce_helper(start, mid, 2 * node, node_start, mid),\n",
        "                    self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n",
        "                )\n",
        "\n",
        "    def reduce(self, start=0, end=None):\n",
        "        \"\"\"Returns result of applying `self.operation`\n",
        "        to a contiguous subsequence of the array.\n",
        "            self.operation(arr[start], operation(arr[start+1], operation(... arr[end])))\n",
        "        Parameters\n",
        "        ----------\n",
        "        start: int\n",
        "            beginning of the subsequence\n",
        "        end: int\n",
        "            end of the subsequences\n",
        "        Returns\n",
        "        -------\n",
        "        reduced: obj\n",
        "            result of reducing self.operation over the specified range of array elements.\n",
        "        \"\"\"\n",
        "        if end is None:\n",
        "            end = self._capacity\n",
        "        if end < 0:\n",
        "            end += self._capacity\n",
        "        end -= 1\n",
        "        return self._reduce_helper(start, end, 1, 0, self._capacity - 1)\n",
        "\n",
        "    def __setitem__(self, idx, val):\n",
        "        # index of the leaf\n",
        "        idx += self._capacity\n",
        "        self._value[idx] = val\n",
        "        idx //= 2\n",
        "        while idx >= 1:\n",
        "            self._value[idx] = self._operation(\n",
        "                self._value[2 * idx],\n",
        "                self._value[2 * idx + 1]\n",
        "            )\n",
        "            idx //= 2\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert 0 <= idx < self._capacity\n",
        "        return self._value[self._capacity + idx]\n",
        "\n",
        "\n",
        "class SumSegmentTree(SegmentTree):\n",
        "    def __init__(self, capacity):\n",
        "        super(SumSegmentTree, self).__init__(\n",
        "            capacity=capacity,\n",
        "            operation=operator.add,\n",
        "            neutral_element=0.0\n",
        "        )\n",
        "\n",
        "    def sum(self, start=0, end=None):\n",
        "        \"\"\"Returns arr[start] + ... + arr[end]\"\"\"\n",
        "        return super(SumSegmentTree, self).reduce(start, end)\n",
        "\n",
        "    def find_prefixsum_idx(self, prefixsum):\n",
        "        \"\"\"Find the highest index `i` in the array such that\n",
        "            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n",
        "        if array values are probabilities, this function\n",
        "        allows to sample indexes according to the discrete\n",
        "        probability efficiently.\n",
        "        Parameters\n",
        "        ----------\n",
        "        perfixsum: float\n",
        "            upperbound on the sum of array prefix\n",
        "        Returns\n",
        "        -------\n",
        "        idx: int\n",
        "            highest index satisfying the prefixsum constraint\n",
        "        \"\"\"\n",
        "        assert 0 <= prefixsum <= self.sum() + 1e-5\n",
        "        idx = 1\n",
        "        while idx < self._capacity:  # while non-leaf\n",
        "            if self._value[2 * idx] > prefixsum:\n",
        "                idx = 2 * idx\n",
        "            else:\n",
        "                prefixsum -= self._value[2 * idx]\n",
        "                idx = 2 * idx + 1\n",
        "        return idx - self._capacity\n",
        "\n",
        "\n",
        "class MinSegmentTree(SegmentTree):\n",
        "    def __init__(self, capacity):\n",
        "        super(MinSegmentTree, self).__init__(\n",
        "            capacity=capacity,\n",
        "            operation=min,\n",
        "            neutral_element=float('inf')\n",
        "        )\n",
        "\n",
        "    def min(self, start=0, end=None):\n",
        "        \"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"\n",
        "\n",
        "        return super(MinSegmentTree, self).reduce(start, end)\n",
        "\n",
        "class LinearSchedule(object):\n",
        "    def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
        "        \"\"\"Linear interpolation between initial_p and final_p over\n",
        "        schedule_timesteps. After this many timesteps pass final_p is\n",
        "        returned.\n",
        "        Parameters\n",
        "        ----------\n",
        "        schedule_timesteps: int\n",
        "            Number of timesteps for which to linearly anneal initial_p\n",
        "            to final_p\n",
        "        initial_p: float\n",
        "            initial output value\n",
        "        final_p: float\n",
        "            final output value\n",
        "        \"\"\"\n",
        "        self.schedule_timesteps = schedule_timesteps\n",
        "        self.final_p = final_p\n",
        "        self.initial_p = initial_p\n",
        "\n",
        "    def value(self, t):\n",
        "        \"\"\"See Schedule.value\"\"\"\n",
        "        fraction = min(float(t) / self.schedule_timesteps, 1.0)\n",
        "        return self.initial_p + fraction * (self.final_p - self.initial_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WBzytNxzvNQ"
      },
      "source": [
        "### Replay memory and Prioritized replay memory (PER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOXPjAgTzvNU"
      },
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, buffer_size, batch_size,is_action_discrete=True):#, seed , action_size\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "        \"\"\"\n",
        "        self.buffer_size = buffer_size\n",
        "        self.is_action_discrete = is_action_discrete\n",
        "        \n",
        "        self._index = 0\n",
        "        self.memory = []\n",
        "        #self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        #print (reward,np.array(reward))\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        #self.memory.append(e)\n",
        "        if self._index >= len(self.memory):\n",
        "            self.memory.append(e)\n",
        "        else:\n",
        "            self.memory[self._index] = e\n",
        "        self._index = (self._index + 1) % self.buffer_size\n",
        "            \n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        if self.is_action_discrete:\n",
        "            actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        else:#action is continuous\n",
        "            actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(\n",
        "            device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(\n",
        "            device)\n",
        "        #print (rewards,np.array[rewards])\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)\n",
        "\n",
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    def __init__(self, buffer_size, batch_size, alpha, is_action_discrete = True):\n",
        "        super(PrioritizedReplayBuffer,self).__init__(buffer_size, batch_size, is_action_discrete)\n",
        "        self.alpha = alpha\n",
        "        self.max_priority = 1.0\n",
        "        #self.next_index =  0\n",
        "\n",
        "        tree_size = 1\n",
        "        while tree_size < buffer_size:\n",
        "            tree_size *= 2\n",
        "        \n",
        "        self.sumtree = SumSegmentTree(tree_size)\n",
        "        self.minsumtree = MinSegmentTree(tree_size)\n",
        "        #self.max_priority = 1.0\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        index = self._index\n",
        "        super().add(state, action, reward, next_state, done)\n",
        "        #print(self.next_index,self.sumtree._capacity)\n",
        "        self.sumtree[index] = self.max_priority ** self.alpha\n",
        "        self.minsumtree[index] = self.max_priority ** self.alpha\n",
        "        #self.next_index = (self.next_index + 1) % self.buffer_size\n",
        "\n",
        "    def sample_proportional(self):\n",
        "        res = []\n",
        "        p_total = self.sumtree.sum(0, len(self.memory) - 1)\n",
        "        every_range_len = p_total / self.batch_size\n",
        "        for i in range(self.batch_size):\n",
        "          mass = random.random() * every_range_len + i * every_range_len\n",
        "          idx = self.sumtree.find_prefixsum_idx(mass)\n",
        "          res.append(idx)\n",
        "        return res\n",
        "\n",
        "    def sample(self,beta):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        indexes = self.sample_proportional()\n",
        "        \n",
        "        weights = []\n",
        "        p_min = self.minsumtree.min() / self.sumtree.sum()\n",
        "        max_weight = (p_min * len(self.memory)) ** (-beta)\n",
        "\n",
        "        for idx in indexes:\n",
        "            p_sample = self.sumtree[idx] / self.sumtree.sum()\n",
        "            weight = (p_sample * len(self.memory)) ** (-beta)\n",
        "            weights.append(weight / max_weight)\n",
        "        weights = torch.from_numpy(np.array(weights)).float().to(device)\n",
        "        \n",
        "        #print (indexes,weights)\n",
        "        experiences = list(itemgetter(*indexes)(self.memory))\n",
        "        \n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(\n",
        "            device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(\n",
        "            device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones, weights, indexes)\n",
        "\n",
        "    def update_priorities(self,indexes, priorities):\n",
        "        for index,priority in zip(indexes,priorities):\n",
        "          self.sumtree[index] = priority ** self.alpha\n",
        "          self.minsumtree[index] = priority ** self.alpha\n",
        "          self.max_priority = max(self.max_priority,priority)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h01Ig_SezvNV"
      },
      "source": [
        "### Q-network for DQN, and Dueling Q-network for DuelingDQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivYnOqG3zvNV"
      },
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, fc1_units=64, fc2_units=64):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            fc1_units (int): Number of nodes in first hidden layer\n",
        "            fc2_units (int): Number of nodes in second hidden layer\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
        "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
        "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class DuelingQNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, fc1_units=64, fc2_units=64):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            fc1_units (int): Number of nodes in first hidden layer\n",
        "            fc2_units (int): Number of nodes in second hidden layer\n",
        "        \"\"\"\n",
        "        super(DuelingQNetwork, self).__init__()\n",
        "        self.action_size = action_size\n",
        "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
        "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
        "        fc3_units = 32\n",
        "        #value\n",
        "        self.fc3_val = nn.Linear(fc2_units,fc3_units)\n",
        "        self.fc4_val = nn.Linear(fc3_units,1)\n",
        "        #advantage\n",
        "        self.fc3_adv = nn.Linear(fc2_units,fc3_units)\n",
        "        self.fc4_adv = nn.Linear(fc3_units,action_size)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        val = F.relu(self.fc3_val(x))\n",
        "        val = self.fc4_val(val)\n",
        "\n",
        "        adv = F.relu(self.fc3_adv(x))\n",
        "        adv = self.fc4_adv(adv)\n",
        "\n",
        "        x = val + adv - adv.mean(1).unsqueeze(1).expand(state.size(0), self.action_size)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKrGOjFqzvNW"
      },
      "source": [
        "### DQN agent, and Double DQN agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91fGE1fzBmSg"
      },
      "source": [
        "class DQNAgent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, prioritized_replay = False, alpha= None, beta = None,prioritized_replay_epsilon = 1e-6,dueling = False):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        if prioritized_replay:\n",
        "          self.prioritized_replay = True\n",
        "          self.alpha = alpha\n",
        "          self.beta = beta\n",
        "          self.prioritized_replay_epsilon = 0.\n",
        "          # Replay memory\n",
        "          self.memory = PrioritizedReplayBuffer(BUFFER_SIZE, BATCH_SIZE, alpha)\n",
        "        else:\n",
        "          self.prioritized_replay = False\n",
        "          self.alpha = None\n",
        "          self.beta = None\n",
        "          self.prioritized_replay_epsilon = prioritized_replay_epsilon\n",
        "          # Replay memory\n",
        "          self.memory = ReplayBuffer(BUFFER_SIZE, BATCH_SIZE)\n",
        "\n",
        "        # Q-Network\n",
        "        if dueling:\n",
        "          self.qnetwork_local = DuelingQNetwork(state_size, action_size).to(device)\n",
        "          self.qnetwork_target = DuelingQNetwork(state_size, action_size).to(device)\n",
        "        else:\n",
        "          self.qnetwork_local = QNetwork(state_size, action_size).to(device)\n",
        "          self.qnetwork_target = QNetwork(state_size, action_size).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        \n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0 \n",
        "\n",
        "    def step(self, state, action, reward, next_state, done,t=0):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        #print(state, action, reward, next_state, done)\n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) \n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                if self.prioritized_replay:\n",
        "                    experiences = self.memory.sample(self.beta.value(t))\n",
        "                else:\n",
        "                    experiences = self.memory.sample()\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        if self.prioritized_replay:\n",
        "            states, actions, rewards, next_states, dones, weights, indexes = experiences\n",
        "        else:\n",
        "            states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get max predicted Q values (for next states) from target model\n",
        "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        # Compute Q targets for current states\n",
        "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        #try this? loss = F.smooth_l1_loss(Q_expected, Q_targets)\n",
        "\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if self.prioritized_replay:\n",
        "            #print(Q_targets.shape)\n",
        "            #print(Q_expected.shape)\n",
        "            td_errors = (Q_targets - Q_expected).squeeze()\n",
        "            #print(td_errors.shape)\n",
        "            #print(weights.shape)\n",
        "            #print(weights.is_cuda,td_errors.is_cuda)\n",
        "            new_prioritizes = weights.cpu()*np.abs(td_errors.detach().cpu()) + self.prioritized_replay_epsilon\n",
        "            #print(new_prioritizes.shape)\n",
        "            #print(len(new_prioritizes),len(indexes))\n",
        "            #assert len(indexes == new_prioritizes)\n",
        "            self.memory.update_priorities(indexes,new_prioritizes)\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter\n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
        "\n",
        "\n",
        "\n",
        "class DDQNAgent(DQNAgent):\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        if self.prioritized_replay:\n",
        "          states, actions, rewards, next_states, dones, weights, indexes = experiences\n",
        "        else:\n",
        "          states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "\n",
        "        # Get max indicies from Q local model, then max predicted Q values (for next states) from target model\n",
        "        Q_indicies_next = self.qnetwork_local(next_states).detach().max(1)[1].unsqueeze(1)\n",
        "        #print(Q_indicies_next.shape,Q_indicies_next)\n",
        "        #print(self.qnetwork_target(next_states).detach().max(1)[0].shape,self.qnetwork_target(next_states).detach().max(1)[0])\n",
        "        Q_targets_next = self.qnetwork_target(next_states).detach().gather(1,Q_indicies_next)\n",
        "        #print(Q_targets_next.shape)\n",
        "        # Compute Q targets for current states\n",
        "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        #try this? loss = F.smooth_l1_loss(Q_expected, Q_targets)\n",
        "\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if self.prioritized_replay:\n",
        "            td_errors = (Q_targets - Q_expected).squeeze()\n",
        "            new_prioritizes = weights.cpu()*np.abs(td_errors.detach().cpu()) + self.prioritized_replay_epsilon\n",
        "            self.memory.update_priorities(indexes,new_prioritizes)\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzx6WoePzvNX"
      },
      "source": [
        "### Soft Q-Network and Policy Network for Soft Actor Critic modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKNECIAnzvNX"
      },
      "source": [
        "from torch.distributions.normal import Normal\n",
        "      \n",
        "class SoftQNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, hidden_units=64, init_w = 3e-3):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            fc1_units (int): Number of nodes in first hidden layer\n",
        "            fc2_units (int): Number of nodes in second hidden layer\n",
        "        \"\"\"\n",
        "        super(SoftQNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size+action_size, hidden_units)\n",
        "        self.fc2 = nn.Linear(hidden_units, hidden_units)\n",
        "        self.fc3 = nn.Linear(hidden_units, 1)\n",
        "        \n",
        "        #small init to layer weights\n",
        "        #self.fc1.weight.data.uniform_(*init_layer(self.fc1))\n",
        "        #self.fc2.weight.data.uniform_(*init_layer(self.fc2))\n",
        "        self.fc3.weight.data.uniform_(-init_w,init_w)\n",
        "        self.fc3.bias.data.uniform_(-init_w,init_w)\n",
        "        \n",
        "        #self.apply(init)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "        #x = torch.cat((state,action),dim=1)\n",
        "        x = torch.cat([state,action],1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "    \n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self,state_size,action_size, hidden_units = 64, init_w=3e-3, log_std_min = -20, log_std_max = 2): #, action_limit\n",
        "        super(PolicyNetwork,self).__init__()\n",
        "        self.log_std_min = log_std_min\n",
        "        self.log_std_max = log_std_max\n",
        "        #self.action_limit = action_limit\n",
        "        \n",
        "        self.fc1 = nn.Linear(state_size,hidden_units)\n",
        "        self.fc2 = nn.Linear(hidden_units,hidden_units)\n",
        "        \n",
        "        self.mean_layer = nn.Linear(hidden_units, action_size)\n",
        "        self.mean_layer.weight.data.uniform_(-init_w, init_w)\n",
        "        self.mean_layer.bias.data.uniform_(-init_w, init_w)\n",
        "        \n",
        "        #small init to last layer weights\n",
        "        self.log_std_layer = nn.Linear(hidden_units,action_size)\n",
        "        self.log_std_layer.weight.data.uniform_(-init_w,init_w)\n",
        "        self.log_std_layer.bias.data.uniform_(-init_w,init_w)\n",
        "        \n",
        "        #print(self.mean_layer,self.mean_layer.parameters())\n",
        "        \n",
        "    def forward(self,state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        mean = self.mean_layer(x)\n",
        "        log_std_unclamped = self.log_std_layer(x)\n",
        "        log_std = torch.clamp(log_std_unclamped, self.log_std_min, self.log_std_max)\n",
        "        #print (mean,log_std)\n",
        "        return mean, log_std\n",
        "    \n",
        "    def sample(self,state,epsilon=1e-6):#deterministic = False):\n",
        "        mean, log_std = self.forward(state)\n",
        "        std = log_std.exp()\n",
        "        \n",
        "        normal_distribution = Normal(mean,std)\n",
        "        e = normal_distribution.rsample()\n",
        "        action = torch.tanh(e)\n",
        "        \n",
        "        log_prob = normal_distribution.log_prob(e) - torch.log(1 - action.pow(2) + epsilon)\n",
        "        log_prob = log_prob.sum(1,keepdim=True)\n",
        "        \n",
        "        return action,log_prob\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYqpZaT2zvNX"
      },
      "source": [
        "### Soft Actor-Critic  agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMwlX90wzvNX"
      },
      "source": [
        "class SACAgent:\n",
        "    def __init__(self, state_size, action_size, alpha, is_auto_alpha = True, q_lr = LR, policy_lr = LR, a_lr = LR, action_prior = \"uniform\"): #, action_range\n",
        "        \"\"\"Initialize an Agent object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.action_range = [ACTION_LOW,ACTION_HIGH]\n",
        "        \n",
        "        self.alpha = alpha\n",
        "        self.is_auto_alpha = is_auto_alpha\n",
        "        self._action_prior = action_prior\n",
        "        \n",
        "        #for the train func. also can be upgraded later on to PER (right now we assume it is false)\n",
        "        self.prioritized_replay = False\n",
        "        \n",
        "        self.q1_network = SoftQNetwork(self.state_size,self.action_size).to(device)\n",
        "        self.q2_network = SoftQNetwork(self.state_size,self.action_size).to(device)\n",
        "        self.q1_target = SoftQNetwork(self.state_size,self.action_size).to(device)\n",
        "        self.q2_target = SoftQNetwork(self.state_size,self.action_size).to(device)\n",
        "        self.policy_network = PolicyNetwork(self.state_size,self.action_size).to(device)\n",
        "        \n",
        "\n",
        "        copy_params(self.q1_network,self.q1_target)\n",
        "        copy_params(self.q2_network,self.q2_target)\n",
        "        \n",
        "        self.q1_optimizer = optim.Adam(self.q1_network.parameters(),lr=q_lr)\n",
        "        self.q2_optimizer = optim.Adam(self.q2_network.parameters(),lr=q_lr)\n",
        "        self.policy_optimizer = optim.Adam(self.policy_network.parameters(),lr=policy_lr)\n",
        "\n",
        "        \n",
        "        #for the auto-temperature\n",
        "        if self.is_auto_alpha:\n",
        "            #self.alpha = 1\n",
        "            self.target_entropy = -torch.prod(torch.Tensor((action_size,)).to(device)).item()#-action_size\n",
        "            self.log_alpha = torch.zeros(1,requires_grad=True, device = device)\n",
        "            self.alpha_optimizer = optim.Adam([self.log_alpha],lr=a_lr)\n",
        "            \n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(BUFFER_SIZE, BATCH_SIZE, is_action_discrete = False)\n",
        "        #self.memory = BasicBuffer(BUFFER_SIZE)\n",
        "        \n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0 \n",
        "        \n",
        "           \n",
        "    def step(self, state, action, reward, next_state, done,t=0):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done) ##\n",
        "        #self.memory.push(state, action, reward, next_state, done)\n",
        "        #print(action,\"makinta\")\n",
        "        # If enough samples are available in memory, get random subset and learn\n",
        "        if len(self.memory) > BATCH_SIZE:\n",
        "            experiences = self.memory.sample() ###\n",
        "            self.learn(experiences, GAMMA)\n",
        "            \n",
        "        #update step count\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        #run state in policy net\n",
        "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
        "        #print(state)\n",
        "        mean,log_std = self.policy_network.forward(state)\n",
        "        std = log_std.exp()\n",
        "        #print(state.is_cuda)\n",
        "        #print(mean,log_std)\n",
        "        #sample from dist\n",
        "        normal_distribution = Normal(mean,std)\n",
        "        e = normal_distribution.sample()\n",
        "        action = torch.tanh(e)\n",
        "        action = action.cpu().detach().squeeze(0).numpy()\n",
        "        \n",
        "        #rescale action\n",
        "        \n",
        "        #action = action * (self.action_range[1] - self.action_range[0]) / 2.0 + (self.action_range[1] + self.action_range[0]) / 2.0\n",
        "        #return action \n",
        "        #rint (action)\n",
        "        a = action * (self.action_range[1] - self.action_range[0]) / 2.0 +\\\n",
        "            (self.action_range[1] + self.action_range[0]) / 2.0\n",
        "        #rint (a)\n",
        "        return a\n",
        "    \n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "        #states = torch.FloatTensor(states).to(device)\n",
        "        #actions = torch.FloatTensor(actions).to(device)\n",
        "        #rewards = torch.FloatTensor(rewards).to(device)\n",
        "        #next_states = torch.FloatTensor(next_states).to(device)\n",
        "        #dones = torch.FloatTensor(dones).to(device)\n",
        "        #dones = dones.view(dones.size(0),-1) ###\n",
        "        #print(states, actions, rewards, next_states, dones)\n",
        "        #print (states.shape, actions.shape, rewards.shape, next_states.shape, dones.shape)\n",
        "        \n",
        "        next_actions, next_log = self.policy_network.sample(next_states)\n",
        "        \n",
        "        Q1_target_next = self.q1_target(next_states, next_actions)\n",
        "        Q2_target_next = self.q2_target(next_states, next_actions)\n",
        "        Q_targets_next = torch.min(Q1_target_next,Q2_target_next) - self.alpha * next_log\n",
        "                 \n",
        "        Q_targets = rewards + gamma * (Q_targets_next) * (1 - dones)\n",
        "        \n",
        "        Q_1 = self.q1_network.forward(states,actions)\n",
        "        Q_2 = self.q2_network.forward(states,actions)\n",
        "        \n",
        "        #calc q-nets loss\n",
        "        Q1_loss = F.mse_loss(Q_1,Q_targets.detach())\n",
        "        Q2_loss = F.mse_loss(Q_2,Q_targets.detach())\n",
        "\n",
        "        #update q-nets params\n",
        "        self.q1_optimizer.zero_grad()\n",
        "        Q1_loss.backward()\n",
        "        self.q1_optimizer.step()\n",
        "        \n",
        "        self.q2_optimizer.zero_grad()\n",
        "        Q2_loss.backward()\n",
        "        self.q2_optimizer.step()\n",
        "        \n",
        "        actions_pred,log_pis = self.policy_network.sample(states)\n",
        "        \n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        #IS THIS THE RIGHT ORDER\n",
        "        if self.t_step == 0:\n",
        "            Q_min = torch.min(self.q1_network.forward(states,actions_pred),self.q2_network.forward(states,actions_pred))\n",
        "            \n",
        "            policy_loss = (self.alpha * log_pis - Q_min).mean()\n",
        "            \n",
        "            self.policy_optimizer.zero_grad()\n",
        "            policy_loss.backward()\n",
        "            self.policy_optimizer.step()\n",
        "\n",
        "            # ------------------- update target network ------------------- #\n",
        "            self.soft_update(self.q1_network, self.q1_target, TAU)     \n",
        "            self.soft_update(self.q2_network, self.q2_target, TAU)  \n",
        "        \n",
        "        if self.is_auto_alpha:\n",
        "            alpha_loss = (self.log_alpha * (- log_pis - self.target_entropy).detach()).mean()\n",
        "            self.alpha_optimizer.zero_grad()\n",
        "            alpha_loss.backward()\n",
        "            self.alpha_optimizer.step()\n",
        "            self.alpha = self.log_alpha.exp()\n",
        "            \n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter\n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param + (1.0 - tau) * target_param)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BovwPUOLzvNY"
      },
      "source": [
        "## Proximal Policy Optimization (PPO)\n",
        "an on-policy algorithm, both discrete and continuous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc4no7cu2ZgM"
      },
      "source": [
        "## PPO Discrete Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr9cO2JB2a-9"
      },
      "source": [
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "class ActorCriticDiscrete(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var):\n",
        "        super(ActorCriticDiscrete, self).__init__()\n",
        "\n",
        "        # actor\n",
        "        self.action_layer = nn.Sequential(\n",
        "                nn.Linear(state_dim, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, action_dim),\n",
        "                nn.Softmax(dim=-1)\n",
        "                )\n",
        "        \n",
        "        # critic\n",
        "        self.value_layer = nn.Sequential(\n",
        "               nn.Linear(state_dim, 128),\n",
        "               nn.ReLU(),\n",
        "               nn.Linear(128, 64),\n",
        "               nn.ReLU(),\n",
        "               nn.Linear(64, 1)\n",
        "               )\n",
        "        \n",
        "    def act(self, state, memory):\n",
        "        state = torch.from_numpy(state).float().to(device) \n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "        \n",
        "        memory.states.append(state)\n",
        "        memory.actions.append(action)\n",
        "        memory.logprobs.append(dist.log_prob(action))\n",
        "        \n",
        "        return action.item()\n",
        "    \n",
        "    def evaluate(self, state, action):\n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        \n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        \n",
        "        state_value = self.value_layer(state)\n",
        "        \n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "        \n",
        "class PPODiscreteAgent:\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip):\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        self.timestep = 0\n",
        "        self.memory = Memory()\n",
        "        \n",
        "        self.policy = ActorCriticDiscrete(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr, betas=betas)\n",
        "        self.policy_old = ActorCriticDiscrete(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "    \n",
        "    def update(self):   \n",
        "        # Monte Carlo estimate of state rewards:\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(self.memory.rewards), reversed(self.memory.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "        \n",
        "        # Normalizing the rewards:\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
        "        \n",
        "        # convert list to tensor\n",
        "        old_states = torch.stack(self.memory.states).to(device).detach()\n",
        "        old_actions = torch.stack(self.memory.actions).to(device).detach()\n",
        "        old_logprobs = torch.stack(self.memory.logprobs).to(device).detach()\n",
        "        \n",
        "        # Optimize policy for K epochs:\n",
        "        for _ in range(self.K_epochs):\n",
        "            # Evaluating old actions and values :\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "            \n",
        "            # Finding the ratio (pi_theta / pi_theta__old):\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "                \n",
        "            # Finding Surrogate Loss:\n",
        "            advantages = rewards - state_values.detach()\n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "            \n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "        \n",
        "        # Copy new weights into old policy:\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "    def step(self, reward, done):\n",
        "        self.timestep += 1 \n",
        "        # Saving reward and is_terminal:\n",
        "        self.memory.rewards.append(reward)\n",
        "        self.memory.is_terminals.append(done)\n",
        "        \n",
        "        # update if its time\n",
        "        if self.timestep % update_timestep == 0:\n",
        "            self.update()\n",
        "            self.memory.clear_memory()\n",
        "            self.timstamp = 0\n",
        "\n",
        "    def act(self, state):\n",
        "        return self.policy_old.act(state, self.memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a-zzixk2-HG"
      },
      "source": [
        "## PPO Continous Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHLqCB5y3BKz"
      },
      "source": [
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "class ActorCriticContinuous(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, action_std):\n",
        "        super(ActorCriticContinuous, self).__init__()\n",
        "        # action mean range -1 to 1\n",
        "        self.actor =  nn.Sequential(\n",
        "                nn.Linear(state_dim, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, action_dim),\n",
        "                nn.ReLU()\n",
        "                )\n",
        "        # critic\n",
        "        self.critic = nn.Sequential(\n",
        "                nn.Linear(state_dim, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 1)\n",
        "                )\n",
        "        self.action_var = torch.full((action_dim,), action_std*action_std).to(device)\n",
        "\n",
        "    \n",
        "    def act(self, state, memory):\n",
        "        action_mean = self.actor(state)\n",
        "        cov_mat = torch.diag(self.action_var).to(device)\n",
        "        \n",
        "        dist = MultivariateNormal(action_mean, cov_mat)\n",
        "        action = dist.sample()\n",
        "        action_logprob = dist.log_prob(action)\n",
        "        \n",
        "        memory.states.append(state)\n",
        "        memory.actions.append(action)\n",
        "        memory.logprobs.append(action_logprob)\n",
        "        \n",
        "        return action.detach()\n",
        "    \n",
        "    def evaluate(self, state, action):   \n",
        "        action_mean = self.actor(state)\n",
        "        \n",
        "        action_var = self.action_var.expand_as(action_mean)\n",
        "        cov_mat = torch.diag_embed(action_var).to(device)\n",
        "        \n",
        "        dist = MultivariateNormal(action_mean, cov_mat)\n",
        "        \n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_value = self.critic(state)\n",
        "        \n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "\n",
        "class PPOContinuousAgent:\n",
        "    def __init__(self, state_dim, action_dim, action_std, lr, betas, gamma, K_epochs, eps_clip):\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        self.time_step = 0\n",
        "        self.memory = Memory()\n",
        "        \n",
        "        self.policy = ActorCriticContinuous(state_dim, action_dim, action_std).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr, betas=betas)\n",
        "        \n",
        "        self.policy_old = ActorCriticContinuous(state_dim, action_dim, action_std).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "    \n",
        "    def select_action(self, state):\n",
        "        state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
        "        return self.policy_old.act(state, self.memory).cpu().data.numpy().flatten()\n",
        "    \n",
        "    def update(self):\n",
        "        # Monte Carlo estimate of rewards:\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(self.memory.rewards), reversed(self.memory.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "        \n",
        "        # Normalizing the rewards:\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
        "        \n",
        "        # convert list to tensor\n",
        "        old_states = torch.squeeze(torch.stack(self.memory.states).to(device), 1).detach()\n",
        "        old_actions = torch.squeeze(torch.stack(self.memory.actions).to(device), 1).detach()\n",
        "        old_logprobs = torch.squeeze(torch.stack(self.memory.logprobs), 1).to(device).detach()\n",
        "        \n",
        "        # Optimize policy for K epochs:\n",
        "        for _ in range(self.K_epochs):\n",
        "            # Evaluating old actions and values :\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "            \n",
        "            # Finding the ratio (pi_theta / pi_theta__old):\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "            # Finding Surrogate Loss:\n",
        "            advantages = rewards - state_values.detach()   \n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "            \n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "        # Copy new weights into old policy:\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "    def step(self, reward, done):\n",
        "        self.time_step += 1\n",
        "        # Saving reward and is_terminals:\n",
        "        self.memory.rewards.append(reward)\n",
        "        self.memory.is_terminals.append(done)\n",
        "        \n",
        "        # update if its time\n",
        "        if self.time_step % update_timestep == 0:\n",
        "            self.update()\n",
        "            self.memory.clear_memory()\n",
        "            self.time_step = 0\n",
        "\n",
        "    def act(self, state):\n",
        "        return self.select_action(state)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqa1xCXvzvNY"
      },
      "source": [
        "### Train function and added parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4x2MWBBzvNY"
      },
      "source": [
        "def train(agent, n_episodes=100, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, agent_type = \"DQN\"):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "\n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "        agent_type (str): determines agent's type (q-learning , sac)\n",
        "    \"\"\"\n",
        "    scores = []  # list containing scores from each episode\n",
        "    avg_scores = [] # list contating avg scores \n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start  # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes + 1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            #choose an action\n",
        "            if agent_type == \"SAC\":\n",
        "                action = agent.act(state)\n",
        "            elif agent_type == \"DQN\":\n",
        "                action_index = agent.act(state, eps)\n",
        "                action= ACTIONS[action_index]\n",
        "            elif agent_type == \"PPO_DISCRETE\":\n",
        "                action_index = agent.act(state)\n",
        "                action= ACTIONS[action_index]\n",
        "            elif agent_type == \"PPO_CONTINUOUS\":\n",
        "                action = agent.act(state)\n",
        "            #do action in environment\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            #observe and learn (by the agent)\n",
        "            if agent_type == \"SAC\":\n",
        "                agent.step(state,action,reward,next_state,done)\n",
        "            elif agent_type == \"DQN\":\n",
        "                if agent.prioritized_replay:\n",
        "                    agent.step(state, action_index, reward, next_state, done,i_episode)\n",
        "                else:\n",
        "                    agent.step(state, action_index, reward, next_state, done)\n",
        "            elif agent_type == \"PPO_DISCRETE\" or \"PPO_CONTINUOUS\":\n",
        "                 agent.step(reward, done)\n",
        "            #accumulate score and move to next state\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            \n",
        "            #stop episode if done\n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        \n",
        "        scores_window.append(score)  # save most recent score\n",
        "        scores.append(score)  # save most recent score\n",
        "        avg_scores.append(np.mean(scores_window)) # save current avg score\n",
        "        \n",
        "        if agent_type == \"DQN\":\n",
        "            eps = max(eps_end, eps_decay * eps)  # decrease epsilon\n",
        "        \n",
        "        \n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        \n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "            \n",
        "        if np.mean(scores_window) >= 200.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode - 100,\n",
        "                                                                                         np.mean(scores_window)))\n",
        "        \n",
        "            #torch.save(agent.state_dict(), '/saved')\n",
        "            break\n",
        "        \n",
        "    return scores,avg_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJwLrkAKzvNZ"
      },
      "source": [
        "TOTAL_TIMESTEPS = 1500 #max timesteps, this should be high enough so convergence happens.\n",
        "RUNS = 3 #how many runs of each agent (with different seed)\n",
        "BETA = LinearSchedule(TOTAL_TIMESTEPS,1.0,INITIAL_BETA) # beta schedule for prioritzed replay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmwyL7BizvNZ"
      },
      "source": [
        "#### Initialize DQN agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5Rry-TspzvNZ"
      },
      "source": [
        "#agents = [DQN,DQN_PER,DQN_DUELING,DQN_DUELING_PER,DDQN,DDQN_PER,DDQN_DUELING,DDQN_DUELING_PER]\n",
        "agents_names = ['DQN','DQN_PER','DQN_DUELING','DQN_DUELING_PER','DDQN','DDQN_PER','DDQN_DUELING','DDQN_DUELING_PER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgH4JghEzvNZ"
      },
      "source": [
        "#### save model scores, averages and time to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T79L_rPqzvNZ"
      },
      "source": [
        "scores = []\n",
        "avg_scores = []\n",
        "times = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kCC8emfzvNa"
      },
      "source": [
        "### Train DQN agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "An5LBab_NHFI",
        "outputId": "fc914ad9-9ee5-44f6-cf03-02befec881fd"
      },
      "source": [
        "for name in agents_names:\n",
        "    for i in range(1,RUNS+1):\n",
        "       #if i == 1 and name == 'DQN':\n",
        "       #    continue\n",
        "        init_seed(i)\n",
        "        if name == 'DQN':\n",
        "            agent = DQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE)\n",
        "        elif name == 'DQN_PER':\n",
        "            agent = DQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,prioritized_replay =True, alpha=ALPHA, beta = BETA)\n",
        "        elif name == 'DQN_DUELING':\n",
        "            agent = DQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,dueling = True)\n",
        "        elif name == 'DQN_DUELING_PER':\n",
        "            agent = DQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,prioritized_replay =True,dueling = True, alpha=ALPHA, beta = BETA)\n",
        "        elif name == 'DDQN':\n",
        "            agent = DDQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE)\n",
        "        elif name == 'DDQN_PER':\n",
        "            agent = DDQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,prioritized_replay =True, alpha=ALPHA, beta = BETA)\n",
        "        elif name == 'DDQN_DUELING':\n",
        "            agent = DDQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,dueling = True)\n",
        "        elif name == 'DDQN_DUELING_PER':\n",
        "            agent = DDQNAgent(STATE_SIZE,DISCRETE_ACTION_SIZE,prioritized_replay =True,dueling = True, alpha=ALPHA, beta = BETA)\n",
        "        \n",
        "        print(name,i)\n",
        "        #append to scores\n",
        "        start = time.time()\n",
        "        score, avg_score = train(agent,TOTAL_TIMESTEPS)\n",
        "        end = time.time()\n",
        "        \n",
        "        scores.append(score)\n",
        "        avg_scores.append(avg_score)\n",
        "        times.append(end - start)\n",
        "        \n",
        "        #save model\n",
        "        torch.save(agent.qnetwork_local.state_dict(), name + '_'+str(i)+'.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DDQN 1\n",
            "Episode 100\tAverage Score: -405.01\n",
            "Episode 200\tAverage Score: -220.81\n",
            "Episode 300\tAverage Score: -113.75\n",
            "Episode 400\tAverage Score: -51.313\n",
            "Episode 500\tAverage Score: 53.033\n",
            "Episode 600\tAverage Score: 111.48\n",
            "Episode 700\tAverage Score: 150.77\n",
            "Episode 800\tAverage Score: 148.34\n",
            "Episode 891\tAverage Score: 201.38\n",
            "Environment solved in 791 episodes!\tAverage Score: 201.38\n",
            "DDQN 2\n",
            "Episode 100\tAverage Score: -409.88\n",
            "Episode 200\tAverage Score: -191.48\n",
            "Episode 300\tAverage Score: -78.685\n",
            "Episode 400\tAverage Score: -69.55\n",
            "Episode 500\tAverage Score: -71.45\n",
            "Episode 600\tAverage Score: 28.597\n",
            "Episode 700\tAverage Score: 130.18\n",
            "Episode 800\tAverage Score: 153.10\n",
            "Episode 900\tAverage Score: 151.58\n",
            "Episode 940\tAverage Score: 200.27\n",
            "Environment solved in 840 episodes!\tAverage Score: 200.27\n",
            "DDQN 3\n",
            "Episode 100\tAverage Score: -387.25\n",
            "Episode 200\tAverage Score: -304.18\n",
            "Episode 300\tAverage Score: -111.43\n",
            "Episode 400\tAverage Score: -65.586\n",
            "Episode 500\tAverage Score: -21.42\n",
            "Episode 600\tAverage Score: 153.20\n",
            "Episode 699\tAverage Score: 200.20\n",
            "Environment solved in 599 episodes!\tAverage Score: 200.20\n",
            "DDQN_DUELING 1\n",
            "Episode 100\tAverage Score: -398.10\n",
            "Episode 200\tAverage Score: -264.99\n",
            "Episode 300\tAverage Score: -100.77\n",
            "Episode 400\tAverage Score: -58.134\n",
            "Episode 500\tAverage Score: -25.29\n",
            "Episode 600\tAverage Score: 86.620\n",
            "Episode 700\tAverage Score: 133.84\n",
            "Episode 800\tAverage Score: 121.05\n",
            "Episode 900\tAverage Score: 148.44\n",
            "Episode 1000\tAverage Score: 157.97\n",
            "Episode 1100\tAverage Score: 178.30\n",
            "Episode 1178\tAverage Score: 200.14\n",
            "Environment solved in 1078 episodes!\tAverage Score: 200.14\n",
            "DDQN_DUELING 2\n",
            "Episode 100\tAverage Score: -418.63\n",
            "Episode 200\tAverage Score: -356.52\n",
            "Episode 300\tAverage Score: -129.28\n",
            "Episode 400\tAverage Score: -90.245\n",
            "Episode 500\tAverage Score: -57.86\n",
            "Episode 600\tAverage Score: -4.050\n",
            "Episode 700\tAverage Score: 79.52\n",
            "Episode 800\tAverage Score: 62.47\n",
            "Episode 900\tAverage Score: 119.88\n",
            "Episode 1000\tAverage Score: 78.54\n",
            "Episode 1100\tAverage Score: 111.54\n",
            "Episode 1200\tAverage Score: 172.73\n",
            "Episode 1277\tAverage Score: 200.73\n",
            "Environment solved in 1177 episodes!\tAverage Score: 200.73\n",
            "DDQN_DUELING 3\n",
            "Episode 100\tAverage Score: -430.08\n",
            "Episode 200\tAverage Score: -226.72\n",
            "Episode 300\tAverage Score: -104.25\n",
            "Episode 400\tAverage Score: -29.959\n",
            "Episode 500\tAverage Score: -18.49\n",
            "Episode 600\tAverage Score: 86.821\n",
            "Episode 700\tAverage Score: 170.47\n",
            "Episode 800\tAverage Score: 181.92\n",
            "Episode 900\tAverage Score: 173.90\n",
            "Episode 946\tAverage Score: 200.30\n",
            "Environment solved in 846 episodes!\tAverage Score: 200.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIgkImiezvNa"
      },
      "source": [
        "#### Save DQN info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QgXZll8zvNb"
      },
      "source": [
        "import json\n",
        "with open('scores.json',\"w\") as file:\n",
        "    json.dump(scores,file,indent = 2)\n",
        "with open('avg_scores.json',\"w\") as file:\n",
        "    json.dump(avg_scores,file,indent = 2)\n",
        "with open('times.json',\"w\") as file:\n",
        "    json.dump(times,file,indent = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYIk2sN4zvNb"
      },
      "source": [
        "Average time calculations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbfM7lewzvNb"
      },
      "source": [
        "lens = []\n",
        "for i in range(len(avg_scores)):\n",
        "    lens.append(len(avg_scores[i]))\n",
        "lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhgbYOylzvNb"
      },
      "source": [
        "avg_time = []\n",
        "avg_len = []\n",
        "for i in range(0,len(lens),3):\n",
        "    avg_len.append((lens[i]+lens[i+1]+lens[i+2])/3)\n",
        "    avg_time.append((times[i]+times[i+1]+times[i+2])/3)\n",
        "print(avg_time)\n",
        "print(avg_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LizCTiCCzvNc"
      },
      "source": [
        "### Initialize policy agents\n",
        "first parameters, then agents. notice TAU and UPDATE_EVERY has changed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTGrAeA4zvNc"
      },
      "source": [
        "#Params for SAC. Alpha is 0.2 acc. to paper, TAU and UPDATE_EVERY are changed.\n",
        "BATCH_SIZE = 64\n",
        "LR = 5e-4\n",
        "ALPHA_SAC = 0.2\n",
        "TAU = 0.01\n",
        "UPDATE_EVERY = 2\n",
        "#BUFFER_SIZE = 100000#int(1e6) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg6HpOe4zvNc"
      },
      "source": [
        "*italicized text*### Train SAC and PPO agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "t-DL_RFmNHFL",
        "outputId": "4fa9234b-0c2e-427c-b792-1a03a116cbbe"
      },
      "source": [
        "sac_scores = []\n",
        "sac_avg_scores = []\n",
        "sac_times = []\n",
        "for i in range(1,RUNS+1):\n",
        "    init_seed(i)\n",
        "    SAC = SACAgent(STATE_SIZE,ACTION_SIZE,ALPHA_SAC)\n",
        "    start = time.time()\n",
        "    score, avg_score = train(SAC,TOTAL_TIMESTEPS,agent_type=\"SAC\")\n",
        "    end = time.time()\n",
        "    sac_scores.append(score)\n",
        "    sac_avg_scores.append(avg_score)\n",
        "    sac_times.append(end - start)\n",
        "    torch.save(SAC.policy_network.state_dict(), \"SAC_\"+str(i)+\".pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -87.45\n",
            "Episode 200\tAverage Score: -37.47\n",
            "Episode 300\tAverage Score: -10.97\n",
            "Episode 400\tAverage Score: 164.18\n",
            "Episode 430\tAverage Score: 200.25\n",
            "Environment solved in 330 episodes!\tAverage Score: 200.25\n",
            "Episode 100\tAverage Score: -110.14\n",
            "Episode 200\tAverage Score: -20.839\n",
            "Episode 300\tAverage Score: 145.27\n",
            "Episode 323\tAverage Score: 200.08\n",
            "Environment solved in 223 episodes!\tAverage Score: 200.08\n",
            "Episode 100\tAverage Score: -196.08\n",
            "Episode 200\tAverage Score: -125.76\n",
            "Episode 300\tAverage Score: -76.430\n",
            "Episode 400\tAverage Score: -46.46\n",
            "Episode 500\tAverage Score: -30.53\n",
            "Episode 600\tAverage Score: 21.954\n",
            "Episode 700\tAverage Score: 164.60\n",
            "Episode 800\tAverage Score: 192.90\n",
            "Episode 808\tAverage Score: 201.71\n",
            "Environment solved in 708 episodes!\tAverage Score: 201.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc0vORM_zvNd"
      },
      "source": [
        "import json\n",
        "with open('sacscores.json',\"w\") as file:\n",
        "    json.dump(sac_scores,file,indent = 2)\n",
        "with open('sacavg_scores.json',\"w\") as file:\n",
        "    json.dump(sac_avg_scores,file,indent = 2)\n",
        "with open('sactimes.json',\"w\") as file:\n",
        "    json.dump(sac_times,file,indent = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLgrzUvK3w2h"
      },
      "source": [
        "##PPO discrete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsmk2qPIzvNd"
      },
      "source": [
        "ppo_scores = []\n",
        "ppo_avg_scores = []\n",
        "ppo_times = []\n",
        "\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = len(ACTIONS) \n",
        "solved_reward = 200         # stop training if avg_reward > solved_reward\n",
        "log_interval = 100          # print avg reward in the interval\n",
        "max_episodes = 2000        # max training episodes\n",
        "max_timesteps = 300       # max timesteps in one episode\n",
        "n_latent_var = 256           # number of variables in hidden layer\n",
        "update_timestep = 1200      # update policy every n timesteps\n",
        "lr = 0.002\n",
        "betas = (0.9, 0.999)\n",
        "gamma = 0.99                # discount factor\n",
        "K_epochs = 4                # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "random_seed = 1 \n",
        "\n",
        "for i in range(1,RUNS+1):\n",
        "    init_seed(i)\n",
        "    PPO = PPODiscreteAgent(state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip)\n",
        "    start = time.time()\n",
        "    score, avg_score = train(PPO,TOTAL_TIMESTEPS,agent_type=\"PPO_DISCRETE\")\n",
        "    end = time.time()\n",
        "    ppo_scores.append(score)\n",
        "    ppo_avg_scores.append(avg_score)\n",
        "    ppo_times.append(end - start)\n",
        "    torch.save(PPO.policy.state_dict(), \"PPO_\"+str(i)+\".pt\")\n",
        "'''\n",
        "ppo_scores = []\n",
        "for i in range(1,RUNS+1):\n",
        "    init_seed(i)\n",
        "    ppo_scores.append(train(PPO,TOTAL_TIMESTEPS,agent_type=\"PPO\"))\n",
        "    torch.save(PPO.*policy_network.state_dict(), \"PPO_\"+str(i)+\".pt\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GyeN9_i33ww"
      },
      "source": [
        "##PPO continous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4ZRJWX38mh"
      },
      "source": [
        "ppo_scores = []\n",
        "ppo_avg_scores = []\n",
        "ppo_times = []\n",
        "\n",
        "solved_reward = 200         # stop training if avg_reward > solved_reward\n",
        "log_interval = 1           # print avg reward in the interval\n",
        "max_episodes = 2000        # max training episodes\n",
        "max_timesteps = 300        # max timesteps in one episode\n",
        "\n",
        "update_timestep = 1200      # update policy every n timesteps\n",
        "action_std = 0.5            # constant std for action distribution (Multivariate Normal)\n",
        "K_epochs = 80               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr = 0.0003                 # parameters for Adam optimizer\n",
        "betas = (0.9, 0.999)\n",
        "\n",
        "random_seed = 1\n",
        "\n",
        "for i in range(1,RUNS+1):\n",
        "    init_seed(i)\n",
        "    PPO =  PPOContinuousAgent(STATE_SIZE, ACTION_SIZE, action_std, lr, betas, gamma, K_epochs, eps_clip)\n",
        "    start = time.time()\n",
        "    score, avg_score = train(PPO,TOTAL_TIMESTEPS,agent_type=\"PPO_CONTINUOUS\")\n",
        "    end = time.time()\n",
        "    ppo_scores.append(score)\n",
        "    ppo_avg_scores.append(avg_score)\n",
        "    ppo_times.append(end - start)\n",
        "    torch.save(PPO.policy.state_dict(), \"PPO_\"+str(i)+\".pt\")\n",
        "'''\n",
        "ppo_scores = []\n",
        "for i in range(1,RUNS+1):\n",
        "    init_seed(i)\n",
        "    ppo_scores.append(train(PPO,TOTAL_TIMESTEPS,agent_type=\"PPO\"))\n",
        "    torch.save(PPO.*policy_network.state_dict(), \"PPO_\"+str(i)+\".pt\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbtZ9QfzzvNd"
      },
      "source": [
        "### Print graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLOTFUkPzvNd"
      },
      "source": [
        "def print_graph(name,i,clr='blue'): \n",
        "    plt.plot(np.arange(len(scores[3*i])), scores[3*i], label= name,color = clr,alpha=0.3)\n",
        "    plt.plot(np.arange(len(avg_scores[3*i])), avg_scores[3*i], label=name + ' average',color = clr)\n",
        "    #plt.figure().add_subplot(111).text(3,8,len(scores[i]))\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Episode #')\n",
        "    plt.legend()\n",
        "    plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGNmUhFNHFM",
        "outputId": "c2de6080-33e7-4ab9-d67a-0ff9fd42c6a5"
      },
      "source": [
        "names = ['DQN','DQN_DUELING','DDQN','DDQN_DUELING']\n",
        "for i in range(4):\n",
        "    print_graph(names[i],i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dd7hU1dW433Uv7QLSi0gRUJSiCHhBjA1FARtqPhNb1OiXqBE1mnyxxp/6JX6JJZrE2Eii0WgUS0xEQbFgD9KLNEFpV0SagpRLuXf//lhzmDNzz/R+We/zzDMz+7R95szZ66yy1xLnHIZhGIaRKmWF7oBhGIZRmpgAMQzDMNLCBIhhGIaRFiZADMMwjLQwAWIYhmGkRYNCdyCXtGvXznXv3r3Q3TAMwygpZsyYsd451z7RevVagHTv3p3p06cXuhuGYRglhYisSGY9M2EZhmEYaWECxDAMw0gLEyCGYRhGWpgAMQzDMNLCBIhhGIaRFiZADMMwjLQwAWIYhmGkhQkQw9iLqK3VlxGbrVth3bpC9yI21dXFcw1NgBhGDli1Ct57r9C9qMvEifDGG6lv5xysWaODa01N4vWrqvI/yDmnr0x5+22YMiXz/eSC2lq9fnPmFLonigkQw8gBs2fDpk2F7kVdamth5866g/uiRfD667G3++wzmDZNB9cJE2DjxrrrrF0LO3bo+6xZMH++tm/dWnfdJUtg6tTk+11dDV9+qf0cPz5YOL/7rvbNY+5cWLo0eH9VVTBjRuLjrlwJK5Kakx3Mzp36m337bfr78AvG5cv1/csv9b22Fj75RH+fQmACxDD2Ql57LfJpfckSHeyqq+Gbb3SQ/vrr8PLoAeqrryK/19TAxx+rUPCejpcvh2XLdAD95pvI9RctqruP2lrtU3W1Ht9vRvrPf2D6dO0nhIWzc2GN6NtvIwXjihWwcGHw+c+aBatXa/9iCYitW/Vc5s6NbN+1C3bvDt4mGk9r8wSZd45BxGqfMgVeeQW2bw8L5Zoa2LBBhfWyZSpECoEJEMNIk02bdKDbvDn2OsmYVGprdaBJxeRTW6sDx7ZtdY+XzOBWUxPctw8/hPff188ffBBuF4lcryxq5Ni5U9+/+SZS2HgD26JFeryvvlJtxsOvybz6qg7Ya9fq96qq8LItW4LPY+bMSK0jHkuW1NWcPvmkroDwWLkyuP2119QUmOh6LVoUFqZVVbB+vZ5jkPa0apUKiepqPdcJE8ICdP16fY8+3kcfRbYVojq5CRDDSBPPjBD9JO0nmZt6+XI1D3kD5qZNkSaP6uq6QmHWLB38Jk8Ot9XUqACYODGp7gcSLZA84gmQL76AN9+Mv99163S9qVNhwYJwu6dReKxapYIRoKIicX9Xr9b3WALGY/t2HdBjmc3Gjw8P1Mny6aeqWURrc+++q9czWgD95z/6HvTA8cUX4WUrVui1nDIl/B+DYDPVrl367pwKoPHjk9eOsoEJEMNIE2/QiB5cg9aJh2eC8XwF770H77wTXv7GG5HaAETawKdN0/cJE8Jmpw0b9AnV26c30KRLtMbhP+eZM5PbR9AA2L69DnieaQbCA2xtLcybl5xm5hekUNfR7wl55yIHZT+x2iEsIP3nsGWLmsh27dLB29PCNm9WjXLHjvh9njVLzX4bN4a1jdrayL77BeNHH9Xdx+LF+r59e7htzZr4x80m9Tqdu2HkkmwJkAahu9AbgIKIdsL697tmTdjs47Fhg75WrICePVUI9elTdx/Oxe//22/DoEF113FOtYdmzWJvG03Qk3FNjWoGntbhxzN1xdKK4uEXmDU14YF/9271pQSxY4cKAg+/A377dhXU/sE5WuC8/jqMGpV8Hz2N03/tvvoqUnNZtCj+Przz9AdsNGyYfB8yxQSIYaRJtgSIx8qVkYPJunX6hJ4M0U/c3lN7bW1YC4kepOfM0UHwiCNi73frVn3Kbts2sj3RwBZEtLnK20+nTvG3ixaOyeAXVsn6SDZsiH+9knmyf+215I4VK0Ivlt8lFkHa2dSpcMAB0KtX7oWJmbAMI038AqS2Nti2nUiAjB8fGUHjN5HEcs77zT2x8AZr/8TBaBPSF1/oMs82H4tvv81tmGg80xFA06ap7W/58romrWRIZn5LtogXeJENPvtMzWO5xgSIYaSJX4DMm6fO0+iBNtbAGx3WGkS0Y/jzzyPf/cTyQ0Tb1NNhx47M5kJkSqomrHnz0jtOPgVIPiKm/GHYucIEiGGkifdkL6LmD6hr53/33bqD+IoVGiqbyDQTbc7wjpEKq1bF962UMoUIW80W6VzLYsQEiGGkgHPqF9i1KzzAeyYsgPLyuttMnhxph/c0iyCfQDTTpoU/N0jTYxk0E7w+4Hd4lxr+OS65IpUAh3QxJ7phpMBnn6lTuV27cJtfgMydW3eymt8E41zYfBWUDiQav+M2SDglQ6YhvEbp0KiRapz9+8P+++f+eKaBGEYKeHblaP+EF/O/dm38iVxz5iQnOIJINzlhfTVhZQNPKKej3XXpkt2+ZAMv6ip63k6uKJgAEZGuIjJZRBaKyHwR+WmovY2IvCEiS0LvrUPtIiJ/FJGlIjJXRAYVqu/G3os34PgH82RMUR6rVqV/7F27wjOWUyGfM5OLmUMOqdvmDbQdOqS+v3wN0qng/T/rvQABdgM/d871AYYCY0SkL3Aj8JZzrhfwVug7wMlAr9DrMuDh/HfZ2NvxblC/UzxZH0Om6c3XrEl+1refTKOLWrfObPtiIUhIZDLQxpv/kyyJ5sCkivf/zEbfkqFgAsQ596Vzbmbo87fAQqAzcAbwRGi1J4AzQ5/PAJ50yhSglYhk+ec3jPh4A45fGCTrm0hnQlw2yDRaKV3fSzExdGiwsEh1jomfbAzS7drFn8iZDH7B6Jni5s/PT+h1UTjRRaQ7MBD4GOjonPsSVMiIiPfzdAb8BoCqUFuCaUiGkT28wdQ/KCc7kPgjqvJJpj6QYjTVpEKHDjqj358vyqN9e/Vr5euJPZomTdIzn+2/f1hArFypptEDD4Tnn9fZ/fPmQfPmKkhyeW4FFyAi0hx4EbjWObdZYp9t0II6z1Yichlq4qJbt27Z6qZhAMGDabHPR4g2sYmk1udSFyAdO+p7tgfSbOwv3VQj69fDyy/rrHsv0WNFRVhItmkDY8fmXjAWVICISENUeDztnPtnqPkrEekU0j46AZ7iXwV09W3eBVgdvU/n3FhgLEBlZWWR39pGsVFVpVlSTzpJnw6jKfXBFPTp1atslwyFejovdrL9uzinc4Z69VIt4oEH4PDD4X/+B/7+d430O/hgePTRSL9WkyZwwgka3detG5x8Mhx9tGokuaZgAkRU1fgrsNA5d59v0cvAxcBvQ+//9rVfJSLPAkcAmzxTl2FkC29y4JYtwQIkiGLXQKLJl0A47LD81+5u1ixY4wrigAMSr5MNOnWKne/L0wanTIG//S1c38Rjxgz44Q/DYeJvvaXvjRtre20t3H57uDzvoYeq+SofkwihsBrIUcCFwDwRmR1quxkVHM+JyH8DK4HvhZZNAE4BlgLbgEvy213DKB0aNtTJZEF1v1MdLNMdXDt1yr8ASaWvbdpkXrf+888139m6ddC3b3D25Pbt4yeMHDMGHo6KKT3xRBgxQn+/SZN0H6NGqfb44Yfwv/+rBa0gbKID6N5dfR/+ia65pGACxDn3AcF+DYDhAes7YExOO2Xs9dQXc80BB0DLltnZVyn9JvH6mu6ynTvVrNm4sc4l2bxZhc/tt8MLL0Sue9llcNpp4e+bN6u5cM0a2Hdfbdu2DZ56Sv0Y/vokv/udmq/89O4N55wT2dajR/xqjfkSHlAETnTDKHXMhFXY4yQ6Zqx+eO3r1sFLL2klyOpquPFGHYSbNNGou9//vm5FyAMPDBecqqjQ9VetUsf1nDn6+dtv6xYC828HKlS+/3049dT059sUUsCbADGMDKnvAiQXA5RzOmAPHpzZXIxoEmkZzumTv2dq+utf4Z57Ite7+mp9b9wYWrXSKoEnnqimoX/9S5ctXarmovvvD4d2V1Wps9tfX+Xgg+HCC9XktHNnWHicfDL86EdwzDHal/HjMz71gmACxDCMuORCgIwbB//4hw7Kf/1rfJOMR00N3HefTpbr1099BKn0dfduuOqquulkmjWDa67RqovPPx8uxLRjR7iW+oUXqoZwySUqgBYvhu9+N3JyaJcucNNNut2778KAAbrPww/XssJebZgVK8JlgvNZfjYXmAAxjHpKItNNvo+/YIGGmTZqBK++qm1btqiN/+CD4Sc/0YE2iB074HvfC3+fPFkH6Ztvjow4CgqzFlGhcdBB4UF8n3009HX//VUL6NVLI/Cuv14rRB5yiPoqVq7UqC7PvCSiGkP79toWlF2gWbNI4SaigrJ5c/0enck5U8yEZRhFRqmZpXJJNgaoxx9XP4O3P+fg1lvhjTc0hHXxYrj2Wn1i37AB+vSB445TbSN63sMvf6mz+l9/XSOUzjor8fH/+EcVHvvvD7/4hQqyI4/UY3nRTKAawcCB+rllSw2LjUWs36VBg70ngaUJEMMoYXbvjp2K/O9/1/DQ447Tp9/ZszXv0tNP6wB8111q509EugJERJ/ix46Ft9/Wto4dtb1nT/V/DBqkYamLF6sfwKvUt3ChvjyOP161hOHD1dw1ZIj6HCZMgDPPDPcxSANZsADuvRfOOAP++7+DzyuXT/HpRn9lY/+5xgSIYRQhzunr4Yf1SdtjxAgd9Hv0UPPK5Mnwhz+o2aS6Wp+at22Diy8OO3P9czH8lRG/9z21+ScjRKKZPx9ee019CrG2//Zb1Sq8olgPPVS3hkZ5ORx7rM6cHjhQw49ra6FFC51Y9957cMopcN55dfc/fLhqFvfeq76JTz/V2djvvadmp969NZJq/HgVLPffr+Ypj0wH3lIKb84VJkAMo8ioqYHf/AamTq27bNKkum3/8z/q2IXImdjnnqvaycSJ+mQ/ZIhqLCNGwG9/q+v84AeqIcQLIfUPlO+/D088Ebb9z5sHf/lLWAv66COt2vj227rd+vUaujpqVPwCTGVlUFkZ2fbjH+srFscfr31//319ReN3lt9xB3TtGilAMiVZH1N9FjQmQAwjBRYvzv0xXnstLDyOOQYuv1xnPB9yiE5KW79eZ5jvu6/OYZgxQ5+2Fy0KC4/zz9eB/c03dZ6Bn9691ccwbpxqJH/7G1x0kfofotm+XU1h48fr/j08O//GjXDDDappfPihRlZ5y089VYtgXXFFtn8hpbxcNbR//lN/h+3b1T/y7ruqyXTsqA771q3VYR7tl8jUhJXsNm3aZL6PYsUEiGH4KPQNvWiROo0POQTuvDPcnwED9P3AA/U1dGjw9rt3q0C56KL4x2ndWgf28nIVDh99pJFFZWVqlnr/fY2Uii6C1aiRCow+fdQX8cgjamIb48sRMWqUhrj+6Efwyivp/Q7J0rZtpJbSsWPd8F4vqWA8zSCX1z3ZnGqpUCxBHiZADKNI2LVL7fSgg2I6g1qDBuooLytLzsTy4x9D584qCKqqtO366yPXv/pqFRYDB9ZN0jdmjOaTmjJFvz/xRGErGObzASAbYdKFfmDJFBMghlEE1NbCz3+uSfduv12d5PnilFPUP7B7t2oj06erltGjh5rERo5UE1osbrpJa7V37py/p/pY5HPwLvXBPxuYADGMIuC119S/8Z3vaGhrLgka+Lz5Dt4ciETrRy+P5yAvFrJtwjINpIA10Q3DUDZu1HQeffvWNR/lgmLIhZUrSqmv8SiV8zANxDAKyOrVGlJbUwM//Wl2Kx6WyiCUTcyElV9MgBhGgdixA267TRP2XXKJFmDKB/VZA4lHtudnxNo+lQipeGawYom0iocJEMMoAK+9pjOzQSOZRo4sbH/iUV8ESDSFdvjXB8wHYhh5ZvbssPA444zcCY9CZ+MtBBbGm19MAzGMAHJlPliwAP7v/3R28q9/raGv+aY+m7BSSVxYzBpIsfUnFiZADCMPOKcpQ156SRMF3n03dOhQ6F7VP7Lhf8gnxdCHTDABYhgBZFMDqarSehjTpul8iZtvzo/w2BtNWKmQr1xY6VAq18gEiGEEkC0BUlOj6dYXL4ZhwzTpYDZDddOhPpqwGjbUVDBeffL6TrFEaJkAMYwc4Rw89ZQKj5/9TAWIkRsOOkiLVKWSrr0YBGOpa4kWhWUYOeLNN+HFF7XwUTEJj1IZnHKNTSTMHBMgRkmyeXO40l028QaFIBNBKmaDzz/XWhV9+2p69EJQ6k+36ZCuaSf6N8lkUmepOfIzwQSIUZK8+646pXNFpjbmp59We/zPf7732OVLjXiD9wEH5Ga/+dxHPjABYhQ9tbXqIM0mO3eqvTy6YFI8vGp/8diwAX7xCxVu55yjRZqKjfroRE+HVOaMBJENR3ap/7bmRDeKnlmzNOlgly560/pTjtfW1o1q2r1bCxwdeii0bBm8z4ULYeVKnZPRrZtuM3cuVFfr8qDBYfLk+P3csQN+9Ss1Xx1zDJx5ZvLnaJQe+YqEOu44LRRWXa1lg4uJktNARGSUiCwWkaUicmOh+2Nkn5oavVG+/VYH49Wrtb2qSgsXff11eN1583S9LVvCbWvX6jqffhq8/x07VHgAzJmj+/f2vXlz7D4l4uGHtb+XXaamqwYFfjzbG30gqSBSGr9FixbQtGn82uqFoqQEiIiUAw8CJwN9gfNEpG9he2Vkk127YMIErZGxYAHMn193nZ07w59XroR33lHtwBv8t2/X94qKsPDxE22KmjFDM+L6iX66nDkzfr8ffxzefhvOOgtOO021on794m9TKMyEpcTLeJuJCSubTvR99kl+X4Wg1ExYQ4ClzrnPAUTkWeAMYEFBe2VkjeiBPIhYsf7vvqtmq9279fuyZfoqL4eOHcPrBWkTa9fWbVu5UmeMN2kSu1/bt2s98cmTdS7CRReFl8XSQHr2hPXrY2s7RmmQaxPWMcfUrUFfbJSaAOkMrPJ9rwKO8K8gIpcBlwF069Ytfz0z8oanYQQxb17dm66mRoXKpk3Qtm1YwMTjm29U+LRooY7woMHi00/hxht1fy1awC23qNDw1m3YMHjfTZuqH+fddxP3I13imWfqq0YRi3S0jEx+o2xl423VKv0+5IuSMmEBQT93xN/DOTfWOVfpnKtsX4whMCVCba06mj1z0c6d6sxOxheQDLt2aU2MDRuysz8/0Saq8nKYPh0++kiPm4wAWbZM3zdvhs8+q7u8qgp+8xs1k11/vZakbd06cp1YcwnKyhIPMn36JO6jUZdUouoyERJNmhQmnUj37vk/ZjxKTQOpArr6vncBAqzcRqasWAFLl+pN1rs3LFqkg+a6ddC4MRx7bGY34KZNOpgvXKgO7z591EzUrl14nWQG+mRwTvsN8OWXqQ0yQbzzDtx3HzRqpEKkV6/wMs+uHs/hmYzztlGjzPoYj/qsgQRd21xoGo0bWxgvlJ4AmQb0EpEewBfAucD5he1S/cSLavIGMi9UdscOfTmX+p//66+hefNI0443v2PhQn3fuDG8zO8szwT/HJI5c/Tp0aOmBpYv1wFhwwb1TXz6Key3n5qlOnZUzaJhQ432+ugjGDdOt73llkjhEYtWrdQk5pGMBgIwdCisWqXRYdkkk0Er+lyKjVQfDoolKWGqOKc+Es8iMGRI5P86X5SUAHHO7RaRq4DXgXLgMedcQJyOkSnejeUJjuhBbNs2Nd9s364+h0SDknPwwQc6AB1zTHj/8bbzh+YGUV4e36RWU6OJDN99VzWQTz9VLaqmJixUNm5MfdBp1gx+//tIx7xHt24qkLzzGzlS9//GG+F1kg0fbd9ehWi6AiRbT7feuRxwgGqKr7ySnf3mgqBrmY6QyNdEwkyO7/eRBP0X80FJCRAA59wEYEKh+7G3Ea0NTJ4cHsB79078JO7dbNFPr5mYk1q0iJwT4u1//nydSLhwYWR0VYcOakMuK1Nnd8OGajLr0EHbmjXTz506qWDctEn3v3GjDuZt2qgJ7NBDY0fH7LefChCPRo3qmuKS1UByRb4cxIUgWz66ZIRDLk1YpaIZlZwAMfLDihWJ1/Fu1kWL1AQUL+gtWlB43zO5Ub7+Wgf2detgyRI1LU2dqssqKnSg/8EP9Mm5bVuNfkqWZs0i/THDh+tx5s5NvZ/RubByMYGtTZtI89/eSqoPJJkM4KUyyOcSEyA5xHvaLoVwvFgke5PMmRMsQL74QrWAqqrIdk/4bNuWWf969oR779VSsRUVmn/q8MNVaMQKo02Hpk3D/qDWretqPh5BA1J0W9Om2RcgQeea7TDeYtc+IPMACY98CYdSn9RZamG8JcX77+urUKxbl7r9fNeuyFnXtbXJ35RBTu+ZM+sKj3nz9JUJNTUwcSIccojW3Bg2TENpL7hATWrZFB4e7dtrbq1DD028brwBqEWL4hsI6guJ0n0cd1zk90xmk6cjZI47DgYNSrxerP+HFxru144LiWkgRcq2bfDee5nNRp0yRd87d469zooVGr3Rrp2aWpYtixQ6ziUfTvv66zBgAHTtGn89v48gmmHD9Al9Qgwv1/btWqjp5Zc17PeYY3QyXzLRUMlw4om6fz9HHqnvDRpo+HI8khUM0et16VJX0OaK+iy8+vQJnrfj0aJF9o7lFyA9eqjPbONGFWKxMje3aKEv5zRvWqq0bQunn55ef3OBaSBFyqpVqg1kO4Rz61YYP15f33yjNv2pU2PPinYuNbPAkiWqHaQb6tmgQXD9jA0b4Ikn4NJL4c9/VtPVSy+pM79Xr7pZd48+WoWBx8EHq58mmpEjI79XVKhQ8s9BDXra84Rkr146eCQiloArK9MBwZ9huNgoJVt/tkxC6ZzzUUfptUymD126JH4YKQVMAylSvEE7OlV5pvid4/7P3hNT9I2za1fsrLZBNG4Ms2drEsN04tL9N9/u3eqgf+MNNQXW1qo2cOGFcPnl4fVOOkn9E2VlmtBw61YVRBUV4XW6d4cDD4RXX408nn/CntffVq10Dsb48bH7OWAAHHZYuL/ezPVYg0fv3ipcg84ziObN4y+PptS0ipNOigxtLkb22y84GadHLgVr3xJJEWsCJA/s2BH89Lt1q/4JgwaLTAWIV9ciGv+f3ktp7jFxot40flauTK2Ykz8SKFYfgtixQ1X6yZO1GNP8+WFHdUUFnHyyPt1dcEHdWdp+QdW+fViA+PG2GTpUs+8GndNJJyXfX4g/aCcaXOKVzj3hhNwm0ctHhcRMHnxatlRzUCr4f694WXajad9e5wq1bx/5oOScBmN4AqRDB/0/ev8b52KfYzauXZcume8jH5gAyQMffqiDQjRvv63vQTZNL0op3Zv9yy+D2+PdWLt3181Km+1KgB5btsAf/qBaUEWFmuo8J3yfPvrq2FFNVUOHqh9n//0Th+L266fr+bUPP+3bw6hR8bWLXHHccWFBFk+A5DoDay4CDKIZNkzfe/YMtvXHE75HHql50lLBP5HuqKN00qpH9Pn6BVTr1sH3n/cA4gmjwYP1/pg/P+yr6tlT0/1E3yMHHKBp2L2Q8vqMCZA8kEwp1GhyYcKqrU38ZJatMMh4fPQRPPCA/i4HHaQ34Iknqp/ippt0kPcG+I4dVShUVCT3W5SVRTpKjzsu+2bAeMQbGP39Clpv0KC6czmSLUqVijklVQESL2tA9+4azBCdIdkTgv36qdBs3FgH261b1ckcpJEH0aBB6jnRWrfW/1LXruo7i9aqjz468YRDz6fWtGn4/m3USIWGJ0DKyvT/G12zRiTsQys102KqmAApAoLKsmYiQGprI2tmbNigN/isWYlv3FwIkF27tDjUnDnqH1m6VLWEn/5UtQs/bdtGfq+szEwAZBJ1M3x47oSPN7D07h1u69y5bsRcvBQV3iTKVEm1UmK0ADn5ZP1dvN+mVSu9rqCDc7Qw8wIIvOioAw9M/tixfv9u3eqaYP0cdJC+B5mC/H33c9JJai3wZ7z9zndUqHvre+ZSL5y2a1cVoKmcU33CBEiR4j0hpTOAzZoV+f2jj8Kfd+yIv202HIObN2sI8qxZaqLyzGLl5Xpj/+AHMHp0sJPdG6Q6dNDtcjWADxuWeCBNZeZ6NMn8jpmGY3bokJ4ACXoq7tw5ccSft13079a1a1iARKe0D9o+3lO5l2bmhBPUxBvr+u+/f3wBkg5NmuhDQ3SbX4Np3FhNoN5v0LBhOMzbT1mZ/qb1vSSRCZAi4vPPVfWvqYE1a7QtHRU4XuRIIlLVQLZtU+fismXqjPzPfzSjbW2tCozBg1WLGDAA+vePHJS9ORe9e6tN+ssvw+d7xBHBx8sWxV4qNN8MGKC/vWee6dUrHDWWTOLLZIgWBn5fRPfuOj/o1FMjj1VWljgaKt8kawJMZsJgqWMCpAjwbtCg+t/5JtkZuK++qsJi/vxIc9thh+nT4+DBai/2BwGMHKmmtPff131UVGhbw4b6PVcO+3zQsqU+cebT5u2/Vqke97jjdPD2NAdvoPYEiD/sOFvhqtF9bNYsLEAOOSSyhrz3nxLROTL9+4cd65WVkfvxmwGN/GICpB6xdWt4QMgV++0Hl1yiqUjatYMzz1Stom9ffYqMNX+hdWt1QjZqBCNGhAcIf1RSso7VbBM9mTAdvElhpVLnvEWL1M2D2dJAvP34td3oBJP+h5Jon0WnTpETVROlLzFyhwmQIiBbT3iLFuU2I+uuXXD11eoMHTNGBUGyg4r/HHNZbS8diq0/2SBWGLMfb1COVfn5iCNUY/SikDIVINHbd+wYNtVGE12PxihO7PKkgXNanS5fx0qWbJWA9YhOPDdpkpqtHnhAn9pFwvH+0UTPXymldBilQrzfNDp0NYimTbWS3eDB+j16gO/QQZ3V2bp2XgCHJ9y6dYs958XzlXnRVKDOa09brG/hsaV6PiZA0mDZMq2Lna2n/WzdoNGTADPFHwK7dSv8858adnvppeH2ffZR01X37pG5faIjU/Y2AZLN881l0aGOHesK+1hP/ZkOcocdVldoHHtscAaAhg01Sm3ffSPbgrTF+vDfOukkOP74QvcidUyApIHn+Nu6VW21XgLBXJDszREdPdWhQ3b78cgjGl31q1/VXTKplxMAACAASURBVHboofryR1hFh3PWh5u8UIwYkZ99edcoOjFltqKw2rSJzB8GGg6baS3vUvhvJUq/3rhx6vnPigHzgaSB94TmnGbNXbRIB/CDDw5ePxfq6c6devN5fYlOEuiZCxLVDU/E0KEaXvvBBzr4+DPcRhP05Nqokfa1FG7ybJCLa52MjybZ3zdeoEKrVhpJ1qdPevs2YhM0V6Q+YBpIGvijSLzBORP/w9q1sSvzBd28zmntjTlzYu+zulrt27F8FMnSvj385jc68Hz/+/HXjR48Tz1VU6NDZpPySpFiHHQTXYPGjXXuQiwHfLHa6Yvxt95bMA0kDfwaSDaYOTO1m9MzV61eHbuORP/+8dNg+ImXWnvSJK01fvrpsaN1PLzfxXtiLivTQWvw4LopSozMaNRItYVFi/R7ov+Pl34kHbJlwsom/r6YACkcpoGkQVAcu/cn3rq1bnqJZG68VG4Cr2Ke5/zcsqXuOn7nYyKaNIFTTqnbvnw5XHGFZhe98MLk9jVwYFjr8PclHxlgiwHvmiQTRpsuTZtqNFIqWp3f3JkqxShA/JgAKRymgaSBXwOJvqnipWhPh+gspxBOe+71Y/Lk9Pc/ZIi+R0fibN+uPo8NG+C551SL2LAhvLyyMrjeR6nUMcgVTZuqGSjbQQypkO2BPpkB2vOVGXsXJkDSwK+B5Lo4z8KFsTN9ZnrseELuL3/RrLlvvx32o/hn/HrZSI26xKtBny5HHKEDdKwEgq1aZZY/LRni7bd9+8QmzlxhGkjhMBNWGgQVAyrEnzhXs3TfeUd9IjfdlLkT3sgOHTrETxl+4IFaSAmy/78wE5YRCxMgaeDdoLW1yd1UIjpXZMaM7PZjy5bsJ2CcORPuu0+zsd5+e3b3beQOkXCG4VyZsEyAGNGYCSsN0tFAvGiZww/Pbl+CyoVGk2zhoQ8+gAcfVIf3jTfuPY7vUsGrQeHPEDB8eDiE3J/Btr5TX8/x+OPzU7M+WxREAxGRe0RkkYjMFZGXRKSVb9lNIrJURBaLyEhf+6hQ21IRubEQ/fbIdhhvrhkyJDjKys/SpXD33erneOCBwtmzjdg0bqwV8vyh202bhgWKN/Bk2wfj/ReKtYZKqdyHydC8eW4j+LJN0gJERI4WkUtCn9uLSI8MjvsGcIhzrj/wKXBTaL99gXOBfsAo4CERKReRcuBB4GSgL3BeaN2C4z0JBUVLRa9TKMrKdHCJVzfhmWe0n3fckVwiPqMwtG0bu5JigwYa3uuvq5ENunbVRIaZlAfOJTbHqHAkJUBE5DbgBkIDPdAQeCrdgzrnJjnnvLnbUwAv+PMM4Fnn3A7n3DJgKTAk9FrqnPvcObcTeDa0btGwdm24GE+x4q/17GfnTvjb37SmR6KcPUZx06hRbh5YitWc2aRJaT2x1zeS1UDOAkYDWwGcc6uBbCm0lwITQ587A6t8y6pCbbHa6yAil4nIdBGZvi6dgtEp4r9ZY6V496+Tq6SLyeBX9f1PqX/5i/pS/uu/8t8nI7cccohWhjSMXJCsANnpnHOAAxCRGFn8w4jImyLyScDrDN86twC7gae9poBduTjtdRudG+ucq3TOVbbPsyE/mYp6EyZk95ipPG16po+DDw4PKjt3wrPP6kCTbQe/UXh69Mi+SasYKLRZ2FCSjcJ6TkQeBVqJyI9RreHP8TZwzsXJ2woicjFwGjA8JJxANYuuvtW6AKtDn2O1Fw2xbNOZ8s03WkL2O99Jbv1YN1dZWeTkwdpaHVyWLoXrr7eb0jCM1EhKA3HO3Qu8ALwIHAz8P+fcA+keVERGoT6V0c45fx7al4FzRaRxyEnfC5gKTAN6iUgPEWmEOtpfTvf4uSJWNMiuXZnt95NPVIhs3gyLFydePxlBUFMDF12kwuO004LrfBhGsWMPPYUl4TNzKALq9ZBGESNna8r8CWgMvCH6D5jinLvCOTdfRJ4DFqCmrTHOuZpQP64CXgfKgcecc1meQpce+fgDe2HDNTV1EyeKpBfG+Pjj8PTTGuL7r3+VVuy5YRjFQUIB4pyrEZFtItLSObcpGwd1zsVMyuCcuxO4M6B9ApBlD0JivvpK35NJjZ6reHT/zHevP8msH4tdu1TjOOIIrXFuT3GGYaRDslb7amCeiLxBKBILwDl3TU56VURMnarvQYkH8zWBydMOgmqwR5eyhfgCYccOTbe+ciU8/LAJD6M0sf9tcZCsAHk19DKiyKcJa8mSzPd17bUwbRp873taZMgwShkTJIUlKQHinHsi5Lw+KNS02DmXoWu4/uHXSLZujb3eZ58ll8PKI9XsqrFuqn/8Ax55ROd7PPWU3XyGYWRGUgJERIYBTwDL0TkZXUXkYufce7nrWmkQaxB+553Y2yxYkNoxUhUgQetPngwXXABHH61pS4p1ZrFhGKVDsias3wEjnHOLAUTkIOAZwKae+fBrIEG+iXRJRYA0b67VAv2sWAE/+pEmSnzxRRMehmFkh2QFSENPeAA45z4VERuG0qSsLDUBk4qpqV+/yKyp8+ZB//76+fnnC1tq1TCM+kWyAmS6iPwV+Hvo+wVAlssj7T00aBCua54MmfgqHnxQ3++7D84+O/39GEYxYn68wpKsAPkJMAa4BvWBvAc8lKtOlRL+P3CyYb2pCpBVqxKvE9Sf3bvhySfh4ovhuusSbztihJ7DG9maLmoYRr0mWQHSAPiDc+4+2DM7PYnUgXsXuZoXkm4qlIkTtU7JqFHJrd+4cXZ9N4Zh1G+Sdc++Bfiz7lcAb2a/O6VHOhpILtVub981NTrno29f+O53U9/eMAwjEclqIE2cc3uyMDnntohI0xz1qeiJJSiKobSmJwDef1/nmjzzjBYZMoz6RDHca0byGshWERnkfRGRSiBOEVej0Nx7L7RqFZyCJR6mgRiGkSzJaiDXAs+LyGq0kNN+wDk561WJUiwmrDlz4NVX4de/hmYJS38ZhmGkR1wNREQGi8i+zrlpQG9gHJpm/TVgWR76V5T4BUWsz4Wiulp9H/vsA2PGFLo3hpFbTGMuLIlMWI8CXsDpkcDNwIPA18DYHParJNmepFEvuqZHJjgH8+dr7q2FC+HQQzWNyj33qAkrHRo21BK3hmEY8Uhkwip3znlJxM8BxjrnXgReFJHZue1a6VFVld/j7dwZPDnwrrvg8svT32+yYb+GUSiKQds3khAgItLAObcbGA5clsK29ZZC/3l37YI77oC5cyPb27bVuR+DBxemX4Zh7F0kEgLPAO+KyHo06up9ABE5EMhKdcJSYfx42Hdf2LQJWrQIt+dbmIhohJUnPL77XTjnHDU7NWgAvXrltz+GYey9xBUgzrk7ReQtoBMwybk9w2UZcHWuO1dsrFmj78n6OrJ97MmTNa3Jf/6jQuOCC+quZ05FY2/C/u+FJZma6FMC2j7NTXeKi2JJ6+Ec/N//wfLl+v0734Hzzy9olwzDMPZeP0YyfPZZYY//5JOakqR/fxUevXurg/vXv4a33w7epliEnmEY9R8TIHHYvbtwx96wAV54QT+/9JL6X+68U0Nz400ONAFi7A0UOpDFUFIslrp3sGoVlJeHa2nEwrnc/ZFffTX8uVUrnRyYTCVBEyDG3oT5QAqLaSABlJfrQFyop5xXXlHtY8gQuPnmyJK2iW4YEyCGYeQL00AC8AbsQggQf0Gn665LrR46QOvW2e+TYRQbTUO5wA88sLD92NsxDSSAZAVItk1YL7ygjnOAH/849USI7dtb6nZj76BBg9QzTRvZxwRIAOXl+p4vc9C0afDEE7BypX4/6yw45ZTgdc3maxhGsVBQE5aI/I+IOBFpF/ouIvJHEVkqInOjapBcLCJLQq+Lc9kvT4Dkw4S1bZvO8Vi5UicHPvssXHJJuA8eyQiOAQNy00fDMIwgCiZARKQrcBKw0td8MtAr9LoMeDi0bhvgNuAIYAhwm4jkzNqfigkrUx54QOd63Huvfm4ao85jIl/I6adDkyaZ98cwDCNZCmnCuh+4Hvi3r+0M4MlQypQpItJKRDoBw4A3vMzAIvIGMArN1ZV1UnGiJytEBg/W+RxTpuj8kl27oFMn+PBDGDoUDjoovpZRVqaCxkxYhmEUCwURICIyGvjCOTdHIkfEzsAq3/eqUFus9qB9X0Yoa3C3bt3S6l8ufCCzZ8OVV9Ztr6iAq67Sz/GEkQkOwzCKjZwJEBF5E9g3YNEtaGGqEUGbBbS5OO11G50bS6jYVWVlZVpGpmQFSLLaR00N3Hqrfr7+emjcGD7+GD79VHNaedl945mgTIAYhlFs5EyAOOdODGoXkUOBHoCnfXQBZorIEFSz6OpbvQuwOtQ+LKr9nax3OoRnwsqWBvLQQ1qn/Oc/h6OP1ragmh0iKrxqamL3yQSJYRjFQt6d6M65ec65Ds657s657qhwGOScWwO8DFwUisYaCmxyzn0JvA6MEJHWIef5iFBbThDR186diddNpIU8/bRODLzwQjj22OSOHUSqEwoNwzByTbENSxOAz4GlwJ+BKwFCzvNfAdNCr//1ldrNCSKZR2GtWQPjxung/8c/Jqc9xFqnQUhXbNw48T4MwzDyQcEnEoa0EO+zA8bEWO8x4LF89EkkHPUU2YfIAb6qKrgO+qxZcNtt4e8PPKAJEQ87TE1ZsYjev5+WLaF7d43cMgzDKAaKTQMpGsrKIjWMf/8bzj47cTXCGTMihUffvtC1a3ifiYhnwurWLZyR13whhmEUmoJrIMWK34TlHPz1r/p51SqdsxGtLaxfD1OnwqRJOsiPHg2ff64JEf37TERFBezYUbfdfCCGYRQbJkBiUFYWjsJ6551w+8cfw/77w49+BF26aBqS7dvh0kvD69x+OwwaRB0SCYGyMjjkEC0mtXBhatsahmHkGxMgAXhRWJ4AeSY03711a3j+eejQATZt0tfHH4crF1ZUwD33wFFHqaYSTTwhMGCAZt9t1kyPEy1AzGRlGEaxYQIkBp4PZNo0jaYaORK+/lrNVP5KhfffH/aL/OMf0K5d7H3GEwJdu8Ze5vUnel9W1tMwjEJihpEA/BrI3LnaduGFMCYqPuyUU8LCY/jwuhl0o0nFDDVwYPrbGoZh5AMblmLgaSDr1kHPnppupHVrLfq0775w6KFwxRVqzoJIH0i8fSZLly6RqU2itz3ooOT3ZRiGkQvMhBUDTwPZuFGd5pWVMH26VvwbOza83n33wdKlsM8+4e38tGkTLruZSEOJR7QA6dULli0LjtgyDMPIB6aBxMDTQLZv10mAsfwXLVoER1x5tG8PHTvq55YtoV+/5PvgP6aZsAzDKDZsWIqBF8a7c2dYu0iHaMHTs2fy2/qd5CZADMMoNmxYioEX5bR1azjdei5IVjCYADEMo9gwH0gMPB+IJ0ByNQ9j5MjkwnFtHohhGMWGPdfGoKwMvv1WEyq2aZP8dqkO9A0ahPNbpbrfZs1SO5ZhGEY2MQESg7IyWLtWP3frllgw5HowDzr+kCG5PaZhGEY8TIDE4JtvYOVK/bzffonX79s3t/0JEiANG2pUVyqOecMwjGxhPpAYbNsW/tymTWINJNc+ilj7N+FhGEahMA0kCVq2TH7dXAkSc6IbhlFsmACJgT81SbyJhB65TmxoYbyGYRQbNizFoHPn8OeKiuS3Mw3EMIy9BRMgMWjcOPy5GAbvYuiDYRiGHxMgMWjUKPJ7oWtvmAAxDKPYMAESA08DSWaSX6p06pT6NiZADMMoNkyAxMATIA0yDHQOGvgrK7OzH8MwjEJiAiQG0QIkWROWOdENw9hbMAESA6/4U7JzQAo1kdAwDKNQ2Ez0GLRsCRdfrHXPITUn+r77wqpV2e2PCRDDMIoNEyAxEIH/+q9wJt5UBUg28B/TBIhhGMVGwUxYInK1iCwWkfkicrev/SYRWRpaNtLXPirUtlREbsxXP1MN383VQF/oMGLDMIxoCqKBiMjxwBlAf+fcDhHpEGrvC5wL9AP2A94UkYNCmz0InARUAdNE5GXn3IL89z4YG+ANw9jbKJQJ6yfAb51zOwCcc6HKG5wBPBtqXyYiSwGv6sVS59znACLybGjdnAsQTzAUWkBYLizDMIqNQg1LBwHHiMjHIvKuiAwOtXcG/O7nqlBbrPaiwYvW6tIl+/vu1w+aNMn+fg3DMDIhZxqIiLwJBLmTbwkdtzUwFBgMPCciPYEgD4IjWNAF6gQichlwGUC3bt1S73gMEmkgFRVw+ulZO1wEHTvmZr+GYRiZkDMB4pw7MdYyEfkJ8E/nnAOmikgt0A7VLLr6Vu0CrA59jtUefdyxwFiAysrKjA1PnuCIzo3lp1evTI8SH4vAMgyjGCmUCetfwAkAISd5I2A98DJwrog0FpEeQC9gKjAN6CUiPUSkEepofzmfHW7XDgYPhlNPjWxv0gR69469nQ3+hmHUVwrlRH8MeExEPgF2AheHtJH5IvIc6hzfDYxxztUAiMhVwOtAOfCYc25+PjrqN11la36HYRhGfaAgAsQ5txP4QYxldwJ3BrRPACbkuGspU+joLMMwjEJhM9FLADOD1W927dpFVVUV1dXVhe6KsZfRpEkTunTpQsM061aYAElAIg3DNBAjU6qqqthnn33o3r07Yk8LRp5wzrFhwwaqqqro0aNHWvuw6WkZkksBYsJp76C6upq2bdua8DDyiojQtm3bjDRfEyAJSDSIJyo41bx55n2wcaX+Y8LDKASZ/u/MhJUB/folnuRnkwANw6ivmABJQDwNpGfP/PXDMAyj2DATVhoMGQLHHFPoXhhG9igvL2fAgAH069ePww47jPvuu4/a2loA3nnnHVq2bMnAgQM5+OCDOfbYY3nllVcith87diy9e/emd+/eVFZW8s477+xZNmzYMCorK/d8nz59OsOGDYvZl0TH++EPf8gLL7wQsU3zkK14+fLlVFRUMGDAgD2vJ598EoDu3buzfv36iO3+9re/cdVVVwFw++2307RpU9auXVtnvwBfffUV559/Pj179uTwww/nyCOP5KWXXop5HnsDpoGkgZmljFwxfz5s2pTdfbZsqebWeFRUVDB79mwA1q5dy/nnn8+mTZu44447ADjmmGP2DOKzZ8/mzDPPpKKiguHDh/PKK6/w6KOP8sEHH9CuXTtmzpzJ6NGj+fjjj+ncufOefU6cOJGTTz45qT7HO14iDjjggD3nkirt2rXjd7/7HXfddVdEu3OOM888k4svvph//OMfAKxYsYKXX85rQoyiwzSQBBRDJJT5V4180qFDB8aOHcuf/vQnXMANMGDAAP7f//t//OlPfwLgrrvu4p577qFdu3YADBo0iEsuuYQHH3xwzza/+MUv+PWvf51Wf6KPl0suvfRSxo0bx8aNGyPa3377bRo1asQVV1yxp23//ffn6quvznmfihnTQAyjiEikKeSLnj17UltbG2HO8TNo0CDuueceAObPn8/hhx8esbyyspLHH398z3fP3DN58mT22WeflPvjP14iPvvsMwYMGLDn+wMPPMAxSdqcmzdvzqWXXsof/vCHPdoX6DkOGjQotU7vBZgGEgMv+266GkjfvnDYYdnrj2HkmyDtI5llsZb/8pe/TFsL8e8vKPTU3+aZsLxXssLD45prruGJJ55g8+bNMdcZM2YMhx12GIMHD465zt6ACZAYHHtsZtsfcABksRyJYeSVzz//nPLycjp06BC4fNasWfTp0weAvn37MmPGjIjlM2fOjHCcA5xwwglUV1czZcqUlPvjP17btm35+uuv9yzbuHHjHvNZNmjVqhXnn38+Dz300J62fv36MXPmzD3fH3zwQd566y3WrVuXteOWIiZASgDzgRj5ZN26dVxxxRVcddVVgU/7c+fO5Ve/+hVjxowB4Prrr+eGG25gw4YNgDq9X3rpJS6//PI6295yyy3cfffdKfUn+njDhg1j3Lhx7Ny5E9BIquOPPz6lfSbiZz/7GY8++ii7d+8GwsLv4Ycf3rPOtm3bsnrMUsR8IAkoBie6YeSa7du3M2DAAHbt2kWDBg248MIL+dnPfrZn+fvvv8/AgQPZtm0bHTp04I9//OOeiKjRo0ezevVqjjrqKHbv3s2aNWuYM2cO7du3r3OcU045JbA9mnjHO+2005gxYwaHH3445eXlHHDAATzyyCN7to32gVx66aVcc801APTv35+yMn1u/v73v0///v0Dj9+uXTvOOuss7r//fkBNZP/617+47rrruPvuu2nfvj3NmjWrE621tyGJbJmlTGVlpZs+fXpa21ZXwxtvaMGok07KcseA8eP1PV4Z3Ndeg127YOTI+BURjdJm4cKFe8wzpc7u3bu55JJLqK2t5amnnrIULSVA0P9PRGY45ypjbLIH00ASUI/lq2FknQYNGvD3v/+90N0w8oQJkBg0bgz77AP15MHQMIqO119/nRtuuCGirUePHnv97O5SwgRIDEQgTrYFwzAyZOTIkYwcObLQ3TAywKKwDMMwjLQwAWIYhmGkhQkQwzAMIy1MgBiGYRhpYQKkBLBQeiOXWC0QqwWSLhaFZRhFxLXXQpqlLGIyYAD8/vexl1stEKVYa4E453DO7ZlBX0wUX48MwygYVgsks1ogW7ZsYfjw4QwaNIhDDz2Uf//73wDccMMNEckZb7/9dn73u98BcM899zB48GD69+/PbbfdBqg21adPH6688koGDRrEqlWr+MlPfkJlZSX9+vXbsx7AhAkT6N27N0cffTTXXHMNp512GgBbt27l0ksvZfDgwQwcOHBPX7KJaSCGUUTE0xTyhdUCSb8WSJMmTXjppZdo0aIF69evZ+jQoYwePZpzzz2Xa6+9liuvvBKA5557jtdee41JkyaxZMkSpk6dinOO0aNH895779GtWzcWL17M448/vkfw3HnnnbRp04aamhqGDx/O3LlzOeigg7j88st577336NGjB+edd96evtx5552ccMIJPPbYY3zzzTcMGTKEE088kWbNmiV1LslgGohhGHWwWiDp1QJxznHzzTfTv39/TjzxRL744gu++uorBg4cyNq1a1m9ejVz5syhdevWdOvWjUmTJjFp0iQGDhzIoEGDWLRoEUuWLAFUyxk6dOiefT/33HMMGjSIgQMHMn/+fBYsWMCiRYvo2bMnPXr0AIgQIJMmTeK3v/0tAwYMYNiwYVRXV7Ny5cqUfo9EmAZSxBx6KHzyCTSwq2TkEX8tkIULF9ZZHlQL5IQTTtizPFYtkFtvvbVka4G8+OKLe74/+OCDrF+/vs45Ajz99NOsW7eOGTNm0LBhQ7p37051dTUAZ599Ni+88AJr1qzh3HPPBVTg3HTTTXVS3y9fvjxCU1i2bBn33nsv06ZNo3Xr1vzwhz+kuro6oaB/8cUXOfjgg9P7MZKgIBqIiAwQkSkiMltEpovIkFC7iMgfRWSpiMwVkUG+bS4WkSWh18WF6He+6dxZM/FaFJaRL6wWSGa1QDZt2kSHDh1o2LAhkydPZsWKFXuWnXvuuTz77LO88MILnH322YCmc3nsscfYsmULAF988UWg6XDz5s00a9aMli1b8tVXXzFx4kQAevfuzeeff87y5csBGDdu3J5tRo4cyQMPPLBHyMyaNSvdnyQmhXq2vRu4wzk3UUROCX0fBpwM9Aq9jgAeBo4QkTbAbUAl4IAZIvKyc+7roJ0bhpE8VgskkkxqgVxwwQWcfvrpVFZWMmDAAHr37r1nWb9+/fj222/p3LkznTp1AmDEiBEsXLiQI488ElA/zFNPPUV5eXnEfg877DAGDhxIv3796NmzJ0cddRSgEXQPPfQQo0aNol27dgwZMmTPNrfeeivXXnst/fv3xzlH9+7d64RgZ0pB6oGIyOvAY865cSJyHnC6c+58EXkUeMc590xovcWoYBkGDHPOXR5qj1gvFpnUA8k1X34JZWXQsWOhe2IUmvpSD8RqgRSGLVu20Lx5c5xzjBkzhl69enHdddclvX0p1gO5FnhdRO5FzWjfCbV3Blb51qsKtcVqr4OIXAZcBtCtiIuShx5ADKPeYLVACsOf//xnnnjiCXbu3MnAgQMDzYe5ImcCRETeBPYNWHQLMBy4zjn3ooh8H/grcCIQ9Mji4rTXbXRuLDAWVANJo+uGYeQYqwWSPa677rqUNI5skjMB4pw7MdYyEXkS+Gno6/PAX0Kfq4CuvlW7AKtD7cOi2t/JUlcNo+A45/Yqk4/VAikOMnVhFGoeyGrguNDnE4Aloc8vAxeForGGApucc18CrwMjRKS1iLQGRoTaDKPkadKkCRs2bMj4ZjaMVHDOsWHDBpo0aZL2PgrlA/kx8AcRaQBUE/JZABOAU4ClwDbgEgDn3EYR+RUwLbTe/zrnIvMNGEaJ0qVLF6qqqli3bl2hu2LsZTRp0oQuXbqkvX1BorDyRTFHYRmGYRQryUZhWSoTwzAMIy1MgBiGYRhpYQLEMAzDSIt67QMRkXXAioQrxqYdsD7hWqVBfToXsPMpdurT+dSnc4Hkzmd/51zCvDP1WoBkiohMT8aRVArUp3MBO59ipz6dT306F8ju+ZgJyzAMw0gLEyCGYRhGWpgAic/YQncgi9SncwE7n2KnPp1PfToXyOL5mA/EMAzDSAvTQAzDMIy0MAFiGIZhpIUJkABEZJSILA7VZr+x0P1JBhHpKiKTRWShiMwXkZ+G2tuIyBuhWvJvhLIZx60/XyyISLmIzBKRV0Lfe4jIx6FzGScijULtjUPfl4aWdy9kv4MQkVYi8oKILApdoyNL/NpcF/qffSIiz4hIk1K6PiLymIisFZFPfG0pXw8RuTi0/hIRubiIzuWe0H9troi8JCKtfMtuCp3LYhEZ6WtPfdxzztnL9wLKgc+AnkAjYA7Qt9D9SqLfnYBBoc/7AJ8CfdF68zeG2m8E7gp9PgWYiBbrGgp8XOhzCDinnwH/AF4JfX8OODf0+RHgJ6HPVwKPhD6fC4wrdN8DzuUJ4Eehz42AVqV6bdBqoMuAuyLuMQAABc5JREFUCt91+WEpXR/gWGAQ8ImvLaXrAbQBPg+9tw59bl0k5zICaBD6fJfvXPqGxrTGQI/QWFee7rhX8D9jsb2AI4HXfd9vAm4qdL/SOI9/AycBi4FOobZOwOLQ50eB83zr71mvGF5o0bC30Hoxr4Ru3vW+m2LPdUJrwxwZ+twgtJ4U+hx859IiNOBKVHupXhuvxHSb0O/9CjCy1K4P0D1q0E3pegDnAY/62iPWK+S5RC07C3g69DliPPOuTbrjnpmw6pJ0/fViJWQiGAh8DHR0WpSL0HuH0GrFfp6/B64HakPf2wLfOOd2h777+7vnXELLN4XWLxZ6AuuAx0Mmub+ISDNK9No4574A7gVWAl+iv/cMSvf6eKR6PYr6Ovm4FNWgIMvnYgKkLknXXy9GRKQ58CJwrXNuc7xVA9qK4jxF5DRgrXNuhr85YFWXxLJioAFqYnjYOTcQ2IqaSGJR1OcT8g2cgZpA9gOaAScHrFoq1ycRsfpf9OclIrcAu4GnvaaA1dI+FxMgdYlVl73oEZGGqPB42jn3z1DzVyLSKbS8E7A21F7M53kUMFpElgPPomas3wOtRKtYQmR/95xLaHlLoJgqVlYBVc65j0PfX0AFSileG4ATgWXOuXXOuV3AP4HvULrXxyPV61HU1ynk1D8NuMCF7FJk+VxMgNRlGtArFFHSCHX6vVzgPiVERAT4K7DQOXefb9HLgBcdcjHqG/Hag+rPFxzn3E3OuS7Oue7o7/+2c+4CYDJwdmi16HPxzvHs0PpF8yTonFsDrBKRg0NNw4EFlOC1CbESGCoiTUP/O+98SvL6+Ej1erwOjBCR1iGtbESoreCIyCjgBmC0c26bb9HLwLmhyLgeQC9gKumOe4V2ZBXjC426+BSNSril0P1Jss9HoyrnXGB26HUKamt+C1gSem8TWl+AB0PnOA+oLPQ5xDivYYSjsHqG/uxLgeeBxqH2JqHvS0PLexa63wHnMQCYHro+/0Kjdkr22gB3AIuAT4C/o1E9JXN9gGdQ/80u9On7v9O5Hqh/YWnodUkRnctS1KfhjQWP+Na/JXQui4GTfe0pj3uWysQwDMNICzNhGYZhGGlhAsQwDMNICxMghmEYRlqYADEMwzDSwgSIYRiGkRYmQAwjBiJSIyKzfa+4GUpF5AoRuSgLx10uIu3S2G6kiNwempcwIdN+GEYiGiRexTD2WrY75wYku7Jz7pFcdiYJjkEn8x0LfFjgvhh7ASZADCNFQilWxgHHh5rOd84tFZHbgS3OuXtF5BrgCjQP0QLn3Lki0gZ4DJ1wtw24zDk3V0TaopPB2qMT7cR3rB8A16Aptj8GrnTO1UT15xw0e2pPNEdVR2CziBzhnBudi9/AMMBMWIYRj4ooE9Y5vmWbnXNDgD+hebqiuREY6JzrjwoS0Nnbs0JtNwNPhtpvAz5wmmjxZaAbgIj0Ac4BjgppQjXABdEHcs6NI1wP4lB0dvhAEx5GrjENxDBiE8+E9Yzv/f6A5XOBp0XkX2jqEtB0M/8F4Jx7W0TaikhL1OT03VD7qyLydWj94cDhwDRNOUUF4QR/0fRCU1AANHXOfZvE+RlGRpgAMYz0cDE+e5yKCobRwK0i0o/4KbOD9iHAE865m+J1RESmA+2ABiKyAOgkIrOBq51z78c/DcNIHzNhGUZ6nON7/49/gYiUAV2dc5PRolitgObAe4RMUCIyDFjvtGaLv/1kNNEiaEK/s0WkQ2hZGxHZP7ojzrlK4FXU/3E3mghvgAkPI9eYBmIYsakIPcl7vOac80J5G4vIx+hD2HlR25UDT4XMUwLc75z7JuRkf1xE5qJOdC91+B3AMyIyE3gXTZeOc26BiPwSmBQSSruAMcCKgL4OQp3tVwL3BSw3jKxj2XgNI0VCUViVzrn1he6LYRQSM2EZhmEYaWEaiGEYhpEWpoEYhmEYaWECxDAMw0gLEyCGYRhGWpgAMQzDMNLCBIhhGIaRFv8fHHAT2YF9HnIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba2M3Qk4zvNe"
      },
      "source": [
        "# func that can average easily.\n",
        "#a = np.convolve(scoresSAC64, np.ones(100)/100, mode='valid')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}